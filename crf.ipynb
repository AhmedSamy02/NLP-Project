{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec,FastText\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow import keras\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Embedding,LSTM,Dense,Input,Bidirectional,Attention,Concatenate,TimeDistributed,GRU,SimpleRNN,Convolution1D,Dropout\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_train = pd.read_json(\"dataset/PIZZA_train.json\", lines=True,)\n",
    "df_dev = pd.read_json(\"dataset/PIZZA_dev.json\", lines=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = main_train.sample(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "pizza = {\"pizza\", \"pizzas\", \"pie\", \"pies\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_num = {\n",
    "    \"zero\": 0, \"one\": 1, \"two\": 2, \"three\": 3, \"four\": 4, \n",
    "    \"five\": 5, \"six\": 6, \"seven\": 7, \"eight\": 8, \"nine\": 9,\n",
    "    \"ten\": 10, \"eleven\": 11, \"twelve\": 12, \"thirteen\": 13,\n",
    "    \"fourteen\": 14, \"fifteen\": 15, \"sixteen\": 16, \"seventeen\": 17,\n",
    "    \"eighteen\": 18, \"nineteen\": 19, \"twenty\": 20,\n",
    "    \"thirty\": 30, \"forty\": 40, \"fifty\": 50, \"sixty\": 60,\n",
    "    \"seventy\": 70, \"eighty\": 80, \"ninety\": 90,\n",
    "    \"hundred\": 100\n",
    "}\n",
    "\n",
    "\n",
    "def words_to_number(word):\n",
    "    word = word.lower().strip()\n",
    "    \n",
    "    # Handle simple numbers directly\n",
    "    if word in word_to_num:\n",
    "        return word_to_num[word]\n",
    "    \n",
    "    # Handle composite numbers (e.g., twenty-one)\n",
    "    if \"-\" in word:\n",
    "        parts = word.split(\"-\")\n",
    "        return sum(word_to_num[part] for part in parts)\n",
    "    \n",
    "    # Handle \"hundred\" cases (e.g., one hundred twenty-three)\n",
    "    if \"hundred\" in word:\n",
    "        parts = word.split(\"hundred\")\n",
    "        hundreds = word_to_num[parts[0].strip()] * 100\n",
    "        if parts[1].strip():  # If there's something after \"hundred\"\n",
    "            return hundreds + words_to_number(parts[1].strip())\n",
    "        return hundreds\n",
    "    \n",
    "    return None  # Return None if the input is not a valid number word\n",
    "\n",
    "def standardize_numbers(sentence):\n",
    "    # Tokenize the sentence\n",
    "    tokens = sentence.split()\n",
    "    \n",
    "    # Replace number words with digits\n",
    "    standardized_tokens = [\n",
    "        str(words_to_number(token)) if words_to_number(token) is not None else token\n",
    "        for token in tokens\n",
    "    ]\n",
    "    \n",
    "    return \" \".join(standardized_tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r\"[^\\w']\", \" \", text)  # Remove non-word characters\n",
    "    text = re.sub(r\"\\s+\", \" \", text)  # Remove multiple spaces\n",
    "    text = text.lower().strip()  # Lowercase and strip whitespace\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemma(text):\n",
    "    text = text.split()\n",
    "    text = [lemmatizer.lemmatize(word) for word in text]\n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTRACTIONS = {\n",
    "    \"n't\": \"not\",\n",
    "    \"'s\": \"is\",\n",
    "    \"'re\": \"are\",\n",
    "    \"'m\": \"am\",\n",
    "    \"'ll\": \"will\",\n",
    "    \"'ve\": \"have\",\n",
    "    \"'d\": \"would\",\n",
    "    \"'em\": \"them\",\n",
    "    \"'all\": \"all\",\n",
    "    \"'cause\": \"because\",\n",
    "    \"'clock\": \"oclock\",\n",
    "    \"'tis\": \"it is\",\n",
    "    \"'twas\": \"it was\",\n",
    "    \"'tween\": \"between\",\n",
    "    \"'twere\": \"it were\",\n",
    "    \"'twould\": \"it would\",\n",
    "    \"'twixt\": \"betwixt\",\n",
    "    \"'twill\": \"it will\",\n",
    "    \"'til\": \"until\",\n",
    "    \"'bout\": \"about\",\n",
    "    \"'cept\": \"except\",\n",
    "    \"'cos\": \"because\",\n",
    "    \"'fore\": \"before\",\n",
    "    \"'round\": \"around\",\n",
    "    \"'n'\": \"and\",\n",
    "    \"'neath\": \"beneath\",\n",
    "    \"'nother\": \"another\",\n",
    "    \"'nuff\": \"enough\",\n",
    "}\n",
    "def expnad_abb2(text):\n",
    "\n",
    "    pattern = re.compile(\n",
    "        r\"(\" + \"|\".join(re.escape(key) for key in CONTRACTIONS.keys()) + r\")\"\n",
    "    )\n",
    "    expanded_text = pattern.sub(lambda x: \" \" + CONTRACTIONS[x.group()], text)\n",
    "    return expanded_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "negation_words = {\n",
    "    \"no\",\n",
    "    \"not\",\n",
    "    \"none\",\n",
    "    \"never\",\n",
    "    \"without\",\n",
    "    \"avoid\",\n",
    "    \"neither\",\n",
    "    \"nor\",\n",
    "    \"hate\",\n",
    "    \"hold\",\n",
    "    \"lack\",\n",
    "    \"any\",\n",
    "    \"nothing\"\n",
    "}\n",
    "pizza = {\"pizza\", \"pizzas\", \"pie\", \"pies\"}\n",
    "\n",
    "stop_negation_words = {\"and\", \"but\"}\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "stop_words = stop_words - negation_words - stop_negation_words - {'all'}\n",
    "stop_words.update({\"would\", \"like\", \"get\", \"want\"})\n",
    "stop_words.update(pizza)\n",
    "\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return \" \".join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "toppings_regex = re.compile(r'(?<=\\(TOPPING\\s)[^)]*(?=\\s)')\n",
    "number_regex = re.compile(r'(?<=\\(NUMBER\\s)[^)]*(?=\\s)')\n",
    "size_regex = re.compile(r'(?<=\\(SIZE\\s)[^)]*(?=\\s)')\n",
    "quantity_regex = re.compile(r'(?<=\\(QUANTITY\\s)[^)]*(?=\\s)')\n",
    "style_regex = re.compile(r'(?<=\\(STYLE\\s)[^)]*(?=\\s)')\n",
    "drink_type_regex = re.compile(r'(?<=\\(DRINKTYPE\\s)[^)]*(?=\\s)')\n",
    "volume_regex = re.compile(r'(?<=\\(VOLUME\\s)[^)]*(?=\\s)')\n",
    "container_type_regex = re.compile(r'(?<=\\(CONTAINERTYPE\\s)[^)]*(?=\\s)')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = set()\n",
    "toppings = set()\n",
    "numbers = set()\n",
    "quantities = set()\n",
    "styles = set()\n",
    "drink_types = set()\n",
    "container_types = set()\n",
    "volumes = set()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sizes.update([item.lower() for sublist in df_train['train.EXR'].apply(lambda x: size_regex.findall(x)) for item in sublist])\n",
    "# toppings.update([item.lower() for sublist in df_train['train.EXR'].apply(lambda x: toppings_regex.findall(x)) for item in sublist])\n",
    "# numbers.update([item.lower() for sublist in df_train['train.EXR'].apply(lambda x: number_regex.findall(x)) for item in sublist])\n",
    "# quantities.update([item.lower() for sublist in df_train['train.EXR'].apply(lambda x: quantity_regex.findall(x)) for item in sublist])\n",
    "# styles.update([item.lower() for sublist in df_train['train.EXR'].apply(lambda x: style_regex.findall(x)) for item in sublist])\n",
    "# drink_types.update([item.lower() for sublist in df_train['train.EXR'].apply(lambda x: drink_type_regex.findall(x)) for item in sublist])\n",
    "# container_types.update([item.lower() for sublist in df_train['train.EXR'].apply(lambda x: container_type_regex.findall(x)) for item in sublist])\n",
    "# volumes.update([item.lower() for sublist in df_train['train.EXR'].apply(lambda x: volume_regex.findall(x)) for item in sublist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes.update([item.lower() for sublist in df_train['train.TOP'].apply(lambda x: size_regex.findall(x)) for item in sublist])\n",
    "toppings.update([item.lower() for sublist in df_train['train.TOP'].apply(lambda x: toppings_regex.findall(x)) for item in sublist])\n",
    "numbers.update([item.lower() for sublist in df_train['train.TOP'].apply(lambda x: number_regex.findall(x)) for item in sublist])\n",
    "quantities.update([item.lower() for sublist in df_train['train.TOP'].apply(lambda x: quantity_regex.findall(x)) for item in sublist])\n",
    "styles.update([item.lower() for sublist in df_train['train.TOP'].apply(lambda x: style_regex.findall(x)) for item in sublist])\n",
    "drink_types.update([item.lower() for sublist in df_train['train.TOP'].apply(lambda x: drink_type_regex.findall(x)) for item in sublist])\n",
    "container_types.update([item.lower() for sublist in df_train['train.TOP'].apply(lambda x: container_type_regex.findall(x)) for item in sublist])\n",
    "volumes.update([item.lower() for sublist in df_train['train.TOP'].apply(lambda x: volume_regex.findall(x)) for item in sublist])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r\"[^\\w']\", \" \", text)  # Remove non-word characters\n",
    "    text = re.sub(r\"\\s+\", \" \", text)  # Remove multiple spaces\n",
    "    text = text.lower().strip()  # Lowercase and strip whitespace\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemma(text):\n",
    "    text = text.split()\n",
    "    text = [lemmatizer.lemmatize(word) for word in text]\n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = list(sizes)\n",
    "toppings = list(toppings)\n",
    "numbers = list(numbers)\n",
    "quantities = list(quantities)\n",
    "styles = list(styles)\n",
    "drink_types = list(drink_types)\n",
    "container_types = list(container_types)\n",
    "volumes = list(volumes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = [lemma(size) for size in sizes]\n",
    "toppings = [lemma(topping) for topping in toppings]\n",
    "numbers = [lemma(number) for number in numbers]\n",
    "quantities = [lemma(quantity) for quantity in quantities]\n",
    "styles = [lemma(style) for style in styles]\n",
    "drink_types = [lemma(drink_type) for drink_type in drink_types]\n",
    "container_types = [lemma(container_type) for container_type in container_types]\n",
    "volumes = [lemma(volume) for volume in volumes]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_toppings = set()\n",
    "i_toppings = set()\n",
    "\n",
    "for topping in toppings:\n",
    "    topping = topping.split()\n",
    "    b_toppings.add(topping[0])\n",
    "    i_toppings.update(topping[1:])\n",
    "\n",
    "b_toppings = list(b_toppings)\n",
    "i_toppings = list(i_toppings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_styles = set()\n",
    "i_styles = set()\n",
    "\n",
    "for style in styles:\n",
    "    style = style.split()\n",
    "    style = [word for word in style if word not in {\"and\", \"with\",'the'}]\n",
    "    b_styles.add(style[0])\n",
    "    i_styles.update(style[1:])\n",
    "\n",
    "b_styles = list(b_styles)\n",
    "i_styles = list(i_styles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_sizes = set()\n",
    "i_sizes = set()\n",
    "\n",
    "for size in sizes:\n",
    "    size = size.split()\n",
    "    size = [word for word in size if word not in {'-'}]\n",
    "    b_sizes.add(size[0])\n",
    "    i_sizes.update(size[1:])\n",
    "\n",
    "b_sizes = list(b_sizes)\n",
    "i_sizes = list(i_sizes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_drink_types = set()\n",
    "i_drink_types = set()\n",
    "\n",
    "for drink_type in drink_types:\n",
    "    drink_type = drink_type.split()\n",
    "    b_drink_types.add(drink_type[0])\n",
    "    i_drink_types.update(drink_type[1:])\n",
    "\n",
    "b_drink_types = list(b_drink_types)\n",
    "i_drink_types = list(i_drink_types)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_volume = set()\n",
    "\n",
    "for volume in volumes:\n",
    "    volume = volume.split('-') \n",
    "    if len(volume) == 1:\n",
    "        volume = volume[0].split()\n",
    "    \n",
    "    i_volume.add(volume[1])\n",
    "    if len(volume) > 2:\n",
    "        i_volume.update(volume[2:])\n",
    "\n",
    "i_volume = list(i_volume)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_adj_noun(text):\n",
    "    # Tokenize text into words\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # Perform POS tagging\n",
    "    pos_tags = pos_tag(words)\n",
    "    \n",
    "    tokens = []\n",
    "    skip_next = False\n",
    "    \n",
    "    for i in range(len(pos_tags) - 1):\n",
    "        if skip_next:\n",
    "            skip_next = False\n",
    "            continue\n",
    "        \n",
    "        word, tag = pos_tags[i]\n",
    "        next_word, next_tag = pos_tags[i + 1]\n",
    "\n",
    "        if next_word in pizza :\n",
    "            tokens.append(word)\n",
    "            continue\n",
    "        \n",
    "        # If current word is an adjective and the next is a noun, combine them\n",
    "        if (word not in ['extra' , 'pineapple'] and tag in ['JJ', 'JJR', 'JJS'] or word == 'all') and next_tag in ['NN', 'NNS', 'NNP', 'NNPS']:\n",
    "            tokens.append(f\"{word}_{next_word}\")\n",
    "            skip_next = True\n",
    "        elif (word == 'seven' and next_word in ['up' , 'ups']):\n",
    "            tokens.append(f\"{word}_{next_word}\")\n",
    "            skip_next = True\n",
    "        else:\n",
    "            tokens.append(word)\n",
    "    \n",
    "    # Add the last word if it wasn't part of an adj+noun pair\n",
    "    if not skip_next:\n",
    "        tokens.append(pos_tags[-1][0])\n",
    "    \n",
    "    return \" \".join(tokens)\n",
    "\n",
    "\n",
    "# tokenize_adj_noun(\"i 'd like a pizza with roasted garlic roasted tomato and yellow peppers hold the thin crust\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('five', 'B-NUMBER'), ('medium', 'B-SIZE'), ('pizzas', 'O'), ('with', 'O'), ('tomato', 'B-TOPPING'), ('and', 'O'), ('ham', 'B-TOPPING'), ('with', 'O'), ('no', 'O'), ('cheese', 'B-NOT-TOPPING')]\n"
     ]
    }
   ],
   "source": [
    "def manual_annotation(text):\n",
    "    # Break down the text and assign tags manually\n",
    "    tokens = text.lower().split()\n",
    "    labels = ['O'] * len(tokens)\n",
    "    \n",
    "    negation = False\n",
    "    \n",
    "    \n",
    "    # Identify numbers\n",
    "    for i, token in enumerate(tokens):\n",
    "        if token in word_to_num or token.isdigit():\n",
    "            labels[i] = 'B-NUMBER'\n",
    "    \n",
    "    # Identify volumes\n",
    "    for i, token in enumerate(tokens):\n",
    "        if token in i_volume:\n",
    "            labels[i-1] = 'B-VOLUME'\n",
    "            labels[i] = 'I-VOLUME'\n",
    "\n",
    "    # Identify styles\n",
    "    for i, token in enumerate(tokens):\n",
    "        if token in negation_words:\n",
    "            negation = True\n",
    "        if token in b_styles:\n",
    "            labels[i] = 'B-STYLE' if not negation else 'B-NOT-STYLE'\n",
    "            if i+1 < len(tokens) and tokens[i+1] in i_styles:\n",
    "                labels[i+1] = 'I-STYLE' if not negation else 'I-NOT-STYLE'\n",
    "            negation = False\n",
    "    \n",
    "    # Identify toppings\n",
    "    for i, token in enumerate(tokens):\n",
    "        if token in negation_words:\n",
    "            negation = True\n",
    "        elif token in b_toppings:\n",
    "            labels[i] = 'B-TOPPING' if not negation else 'B-NOT-TOPPING'\n",
    "            negation = False\n",
    "\n",
    "    for i, token in enumerate(tokens):\n",
    "        if token in i_toppings :\n",
    "            labels[i] = 'I-NOT-TOPPING' if labels[i-1] == 'B-NOT-TOPPING' else 'I-TOPPING' if labels[i-1] == 'B-TOPPING' else labels[i]\n",
    "    \n",
    "    # Identify sizes\n",
    "    for i, token in enumerate(tokens):\n",
    "        if token in ['sized', 'size']:\n",
    "            labels[i] = 'I-SIZE'\n",
    "            labels[i-1] = 'B-SIZE'\n",
    "        if token in b_sizes:\n",
    "            labels[i] = 'B-SIZE'\n",
    "\n",
    "        # Identify drink orders\n",
    "    for i, token in enumerate(tokens):\n",
    "        if token in b_drink_types:\n",
    "            labels[i] = 'B-DRINKTYPE'\n",
    "            if i+1 < len(tokens) and tokens[i+1] in i_drink_types:\n",
    "                labels[i+1] = 'I-DRINKTYPE'\n",
    "\n",
    "    # Identify quantities\n",
    "    for i, token in enumerate(tokens):\n",
    "        if token in quantities:\n",
    "            labels[i] = 'B-QUANTITY'\n",
    "            if i+1 < len(tokens) and tokens[i+1] in quantities:\n",
    "                labels[i+1] = 'I-QUANTITY'\n",
    "\n",
    "    # Identify containers\n",
    "    for i, token in enumerate(tokens):\n",
    "        if token in container_types:\n",
    "            labels[i] = 'B-CONTAINER'\n",
    "            if i+1 < len(tokens) and tokens[i+1] in container_types:\n",
    "                labels[i+1] = 'I-CONTAINER'\n",
    "    \n",
    "   \n",
    "\n",
    "                \n",
    "    return labels\n",
    "\n",
    "# Example usage\n",
    "text = \"five medium pizzas with tomato and ham with no cheese\"\n",
    "# text = tokenize_adj_noun(text)\n",
    "labels = manual_annotation(text)\n",
    "print(list(zip(text.split(), labels)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_data(texts):\n",
    "    labeled_texts = []\n",
    "    labeled_labels = []\n",
    "    \n",
    "    for text in texts:\n",
    "        # text = tokenize_adj_noun(text)\n",
    "        labels = manual_annotation(text)\n",
    "        labeled_texts.append(text)\n",
    "        labeled_labels.append(\" \".join(labels))\n",
    "\n",
    "    \n",
    "    return labeled_texts, labeled_labels\n",
    "# Prepare multiple training examples\n",
    "# training_texts = [\n",
    "#     \"balsamic glaze and a sprite and three eight ounce fantas and three sprites\",\n",
    "#     \"two pepperoni pizzas and one margherita with olive oil\",\n",
    "#     \"three cokes and a small pizza with mushrooms\"\n",
    "# ]\n",
    "\n",
    "# Generate training data\n",
    "\n",
    "\n",
    "X_train, y_train = generate_training_data(df_train['train.SRC'].apply(clean_text).apply(lemma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_crf = pd.DataFrame({'data': X_train, 'labels': y_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = [\n",
    "    'O',\n",
    "    'B-DRINKORDER', 'I-DRINKORDER',\n",
    "    'B-PIZZAORDER', 'I-PIZZAORDER',\n",
    "    'B-NUMBER', 'I-NUMBER',\n",
    "    'B-DRINKTYPE', 'I-DRINKTYPE',\n",
    "    'B-VOLUME', 'I-VOLUME',\n",
    "    'B-TOPPING', 'I-TOPPING',\n",
    "    'B-SIZE', 'I-SIZE',\n",
    "    'B-QUANTITY', 'I-QUANTITY',\n",
    "    'B-STYLE', 'I-STYLE',\n",
    "    'B-CONTAINER', 'I-CONTAINER',\n",
    "    'B-NOT-TOPPING', 'I-NOT-TOPPING',\n",
    "    'B-NOT-STYLE' , 'I-NOT-STYLE'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tokinezer = Tokenizer(oov_token = \"<OOV>\")\n",
    "input_tokinezer.fit_on_texts(X_train)\n",
    "X_train = input_tokinezer.texts_to_sequences(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = [y.split() for y in y_train]\n",
    "y_train = [[tags.index(tag) for tag in y] for y in y_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = max([len(x) for x in X_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pad_sequences(y_train,max_len, padding='post')\n",
    "X_train = pad_sequences(X_train,max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(len(input_tokinezer.word_index)+1,100))\n",
    "model.add(Convolution1D(128, 5,padding = 'same' ,activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(GRU(100,return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(len(tags), activation='softmax')))\n",
    "model.compile('rmsprop', 'sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_14 (Embedding)    (None, None, 100)         25700     \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, None, 128)         64128     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, None, 128)         0         \n",
      "                                                                 \n",
      " gru_3 (GRU)                 (None, None, 100)         69000     \n",
      "                                                                 \n",
      " time_distributed_4 (TimeDi  (None, None, 25)          2525      \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 161353 (630.29 KB)\n",
      "Trainable params: 161353 (630.29 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "625/625 [==============================] - 41s 66ms/step - loss: 0.0110 - val_loss: 0.0082\n",
      "Epoch 2/5\n",
      "625/625 [==============================] - 35s 55ms/step - loss: 0.0084 - val_loss: 0.0075\n",
      "Epoch 3/5\n",
      "625/625 [==============================] - 34s 55ms/step - loss: 0.0077 - val_loss: 0.0073\n",
      "Epoch 4/5\n",
      "625/625 [==============================] - 35s 55ms/step - loss: 0.0074 - val_loss: 0.0070\n",
      "Epoch 5/5\n",
      "625/625 [==============================] - 35s 56ms/step - loss: 0.0073 - val_loss: 0.0071\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, y_train, batch_size=128, epochs=5, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.plot(hist.history['accuracy'])\n",
    "# plt.plot(hist.history['val_accuracy'])\n",
    "# plt.title('Model accuracy')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i want to order two medium pizza with sausage and black olive and two medium pizza with pepperoni and extra cheese and three large pizza with pepperoni and sausage\n"
     ]
    }
   ],
   "source": [
    "x_test = \"i want to order two medium pizzas with sausage and black olives and two medium pizzas with pepperoni and extra cheese and three large pizzas with pepperoni and sausage\"\n",
    "x_test = clean_text(x_test)\n",
    "x_test = lemma(x_test)\n",
    "print(x_test)\n",
    "x_test = input_tokinezer.texts_to_sequences([x_test])\n",
    "x_test = pad_sequences(x_test,max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "Original Sentence: two medium pizza with sausage and black olive and two medium pizza with pepperoni and extra cheese and three large pizza with pepperoni and sausage\n",
      "Predicted Tags: ['B-NUMBER', 'B-SIZE', 'O', 'O', 'B-TOPPING', 'O', 'B-TOPPING', 'I-TOPPING', 'O', 'B-NUMBER', 'B-SIZE', 'O', 'O', 'B-TOPPING', 'O', 'B-QUANTITY', 'B-TOPPING', 'O', 'B-NUMBER', 'B-SIZE', 'O', 'O', 'B-TOPPING', 'O', 'B-TOPPING']\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "y_pred = np.argmax(y_pred, axis=-1)\n",
    "\n",
    "# Convert the predicted indices back to tags\n",
    "pred_tags = [tags[idx] for idx in y_pred[0]]\n",
    "\n",
    "# Print the original sentence and the tags\n",
    "original_sentence = [input_tokinezer.index_word[idx] for idx in x_test[0] if idx != 0]\n",
    "print(\"Original Sentence:\", \" \".join(original_sentence))\n",
    "print(\"Predicted Tags:\", pred_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\Yara\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1377, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\Yara\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1360, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Yara\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1349, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\Yara\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1127, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\Yara\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1185, in compute_loss\n        return self.compiled_loss(\n    File \"c:\\Users\\Yara\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\Yara\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\Yara\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\Yara\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py\", line 2221, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"c:\\Users\\Yara\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py\", line 5575, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (1, 25, 25) and (1, 21, 25) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[269], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m sent \u001b[38;5;241m=\u001b[39m sent[np\u001b[38;5;241m.\u001b[39mnewaxis,:] \n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sent\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m: \u001b[38;5;66;03m#ignore 1 word sentences\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_on_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43msent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Yara\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:2763\u001b[0m, in \u001b[0;36mModel.train_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[0;32m   2759\u001b[0m     iterator \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39msingle_batch_iterator(\n\u001b[0;32m   2760\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy, x, y, sample_weight, class_weight\n\u001b[0;32m   2761\u001b[0m     )\n\u001b[0;32m   2762\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_train_function()\n\u001b[1;32m-> 2763\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2765\u001b[0m logs \u001b[38;5;241m=\u001b[39m tf_utils\u001b[38;5;241m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[0;32m   2766\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict:\n",
      "File \u001b[1;32mc:\\Users\\Yara\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filet47gs_lb.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Yara\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:1360\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function\u001b[1;34m(model, iterator)\u001b[0m\n\u001b[0;32m   1356\u001b[0m     run_step \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mfunction(\n\u001b[0;32m   1357\u001b[0m         run_step, jit_compile\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, reduce_retracing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1358\u001b[0m     )\n\u001b[0;32m   1359\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(iterator)\n\u001b[1;32m-> 1360\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1361\u001b[0m outputs \u001b[38;5;241m=\u001b[39m reduce_per_replica(\n\u001b[0;32m   1362\u001b[0m     outputs,\n\u001b[0;32m   1363\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy,\n\u001b[0;32m   1364\u001b[0m     reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_reduction_method,\n\u001b[0;32m   1365\u001b[0m )\n\u001b[0;32m   1366\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32mc:\\Users\\Yara\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:1349\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function.<locals>.run_step\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_step\u001b[39m(data):\n\u001b[1;32m-> 1349\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1350\u001b[0m     \u001b[38;5;66;03m# Ensure counter is updated only if `train_step` succeeds.\u001b[39;00m\n\u001b[0;32m   1351\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n",
      "File \u001b[1;32mc:\\Users\\Yara\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:1127\u001b[0m, in \u001b[0;36mModel.train_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1125\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[0;32m   1126\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(x, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m-> 1127\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_target_and_loss(y, loss)\n\u001b[0;32m   1129\u001b[0m \u001b[38;5;66;03m# Run backwards pass.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Yara\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:1185\u001b[0m, in \u001b[0;36mModel.compute_loss\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute the total loss, validate it, and return it.\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m \n\u001b[0;32m   1136\u001b[0m \u001b[38;5;124;03mSubclasses can optionally override this method to provide custom loss\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1182\u001b[0m \u001b[38;5;124;03m  is the case when called by `Model.test_step`).\u001b[39;00m\n\u001b[0;32m   1183\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1184\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m x  \u001b[38;5;66;03m# The default implementation does not use `x`.\u001b[39;00m\n\u001b[1;32m-> 1185\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompiled_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1186\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregularization_losses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlosses\u001b[49m\n\u001b[0;32m   1187\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Yara\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\compile_utils.py:277\u001b[0m, in \u001b[0;36mLossesContainer.__call__\u001b[1;34m(self, y_true, y_pred, sample_weight, regularization_losses)\u001b[0m\n\u001b[0;32m    275\u001b[0m y_t, y_p, sw \u001b[38;5;241m=\u001b[39m match_dtype_and_rank(y_t, y_p, sw)\n\u001b[0;32m    276\u001b[0m sw \u001b[38;5;241m=\u001b[39m losses_utils\u001b[38;5;241m.\u001b[39mapply_mask(y_p, sw, losses_utils\u001b[38;5;241m.\u001b[39mget_mask(y_p))\n\u001b[1;32m--> 277\u001b[0m loss_value \u001b[38;5;241m=\u001b[39m \u001b[43mloss_obj\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    279\u001b[0m total_loss_mean_value \u001b[38;5;241m=\u001b[39m loss_value\n\u001b[0;32m    280\u001b[0m \u001b[38;5;66;03m# Correct for the `Mean` loss metrics counting each replica as a\u001b[39;00m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;66;03m# batch.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Yara\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:143\u001b[0m, in \u001b[0;36mLoss.__call__\u001b[1;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    139\u001b[0m     call_fn \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39m__internal__\u001b[38;5;241m.\u001b[39mautograph\u001b[38;5;241m.\u001b[39mtf_convert(\n\u001b[0;32m    140\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall, tf\u001b[38;5;241m.\u001b[39m__internal__\u001b[38;5;241m.\u001b[39mautograph\u001b[38;5;241m.\u001b[39mcontrol_status_ctx()\n\u001b[0;32m    141\u001b[0m     )\n\u001b[1;32m--> 143\u001b[0m losses \u001b[38;5;241m=\u001b[39m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m in_mask \u001b[38;5;241m=\u001b[39m losses_utils\u001b[38;5;241m.\u001b[39mget_mask(y_pred)\n\u001b[0;32m    146\u001b[0m out_mask \u001b[38;5;241m=\u001b[39m losses_utils\u001b[38;5;241m.\u001b[39mget_mask(losses)\n",
      "File \u001b[1;32mc:\\Users\\Yara\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:270\u001b[0m, in \u001b[0;36mLossFunctionWrapper.call\u001b[1;34m(self, y_true, y_pred)\u001b[0m\n\u001b[0;32m    263\u001b[0m     y_pred, y_true \u001b[38;5;241m=\u001b[39m losses_utils\u001b[38;5;241m.\u001b[39msqueeze_or_expand_dimensions(\n\u001b[0;32m    264\u001b[0m         y_pred, y_true\n\u001b[0;32m    265\u001b[0m     )\n\u001b[0;32m    267\u001b[0m ag_fn \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39m__internal__\u001b[38;5;241m.\u001b[39mautograph\u001b[38;5;241m.\u001b[39mtf_convert(\n\u001b[0;32m    268\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn, tf\u001b[38;5;241m.\u001b[39m__internal__\u001b[38;5;241m.\u001b[39mautograph\u001b[38;5;241m.\u001b[39mcontrol_status_ctx()\n\u001b[0;32m    269\u001b[0m )\n\u001b[1;32m--> 270\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mag_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fn_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Yara\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2221\u001b[0m, in \u001b[0;36mcategorical_crossentropy\u001b[1;34m(y_true, y_pred, from_logits, label_smoothing, axis)\u001b[0m\n\u001b[0;32m   2213\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m y_true \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m label_smoothing) \u001b[38;5;241m+\u001b[39m (\n\u001b[0;32m   2214\u001b[0m         label_smoothing \u001b[38;5;241m/\u001b[39m num_classes\n\u001b[0;32m   2215\u001b[0m     )\n\u001b[0;32m   2217\u001b[0m y_true \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39m__internal__\u001b[38;5;241m.\u001b[39msmart_cond\u001b[38;5;241m.\u001b[39msmart_cond(\n\u001b[0;32m   2218\u001b[0m     label_smoothing, _smooth_labels, \u001b[38;5;28;01mlambda\u001b[39;00m: y_true\n\u001b[0;32m   2219\u001b[0m )\n\u001b[1;32m-> 2221\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcategorical_crossentropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2222\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_logits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_logits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\n\u001b[0;32m   2223\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Yara\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:5575\u001b[0m, in \u001b[0;36mcategorical_crossentropy\u001b[1;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[0;32m   5573\u001b[0m target \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(target)\n\u001b[0;32m   5574\u001b[0m output \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(output)\n\u001b[1;32m-> 5575\u001b[0m \u001b[43mtarget\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_is_compatible_with\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5577\u001b[0m output, from_logits \u001b[38;5;241m=\u001b[39m _get_logits(\n\u001b[0;32m   5578\u001b[0m     output, from_logits, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   5579\u001b[0m )\n\u001b[0;32m   5580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m from_logits:\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\Yara\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1377, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\Yara\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1360, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Yara\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1349, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\Yara\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1127, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\Yara\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1185, in compute_loss\n        return self.compiled_loss(\n    File \"c:\\Users\\Yara\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\Yara\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\Yara\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\Yara\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py\", line 2221, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"c:\\Users\\Yara\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py\", line 5575, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (1, 25, 25) and (1, 21, 25) are incompatible\n"
     ]
    }
   ],
   "source": [
    "import progressbar\n",
    "n_epochs = 10\n",
    "n_classes = len(tags)\n",
    "\n",
    "for i in range(n_epochs):\n",
    "    print(\"Training epoch {}\".format(i))\n",
    "    \n",
    "    bar = progressbar.ProgressBar(maxval=len(X_train))\n",
    "    for n_batch, sent in bar(enumerate(X_train)):\n",
    "        label = y_train[n_batch]\n",
    "        # Make labels one hot\n",
    "        label = np.eye(n_classes)[label][np.newaxis,:] \n",
    "        # View each sentence as a batch\n",
    "        sent = sent[np.newaxis,:] \n",
    "        \n",
    "        if sent.shape[1] > 1: #ignore 1 word sentences\n",
    "            model.train_on_batch(sent, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_units = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(max_len,))\n",
    "embedding_layer = Embedding(len(input_tokinezer.word_index)+1, hidden_units, input_length=max_len)(input_layer)\n",
    "lstm = LSTM(hidden_units, return_sequences=True)(embedding_layer)\n",
    "lstm = LSTM(hidden_units, return_sequences=True)(lstm)\n",
    "output_layer = Dense(len(tags), activation='softmax')(lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 24)]              0         \n",
      "                                                                 \n",
      " embedding_7 (Embedding)     (None, 24, 128)           32896     \n",
      "                                                                 \n",
      " lstm_11 (LSTM)              (None, 24, 128)           131584    \n",
      "                                                                 \n",
      " lstm_12 (LSTM)              (None, 24, 128)           131584    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 24, 25)            3225      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 299289 (1.14 MB)\n",
      "Trainable params: 299289 (1.14 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs = input_layer, outputs = output_layer)    \n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "313/313 - 16s - loss: 0.7082 - accuracy: 0.8255 - 16s/epoch - 51ms/step\n",
      "Epoch 2/10\n",
      "313/313 - 11s - loss: 0.0499 - accuracy: 0.9868 - 11s/epoch - 37ms/step\n",
      "Epoch 3/10\n",
      "313/313 - 12s - loss: 0.0193 - accuracy: 0.9933 - 12s/epoch - 38ms/step\n",
      "Epoch 4/10\n",
      "313/313 - 14s - loss: 0.0138 - accuracy: 0.9942 - 14s/epoch - 44ms/step\n",
      "Epoch 5/10\n",
      "313/313 - 13s - loss: 0.0117 - accuracy: 0.9944 - 13s/epoch - 41ms/step\n",
      "Epoch 6/10\n",
      "313/313 - 12s - loss: 0.0109 - accuracy: 0.9944 - 12s/epoch - 40ms/step\n",
      "Epoch 7/10\n",
      "313/313 - 13s - loss: 0.0104 - accuracy: 0.9946 - 13s/epoch - 41ms/step\n",
      "Epoch 8/10\n",
      "313/313 - 13s - loss: 0.0099 - accuracy: 0.9948 - 13s/epoch - 40ms/step\n",
      "Epoch 9/10\n",
      "313/313 - 13s - loss: 0.0099 - accuracy: 0.9947 - 13s/epoch - 41ms/step\n",
      "Epoch 10/10\n",
      "313/313 - 13s - loss: 0.0097 - accuracy: 0.9948 - 13s/epoch - 42ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x19bab27de90>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = generate_training_data(df_dev['dev.SRC'].apply(clean_text).apply(lemma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = input_tokinezer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = [y.split() for y in y_test]\n",
    "y_test = [[tags.index(tag) for tag in y] for y in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = pad_sequences(y_test,max_len, padding='post')\n",
    "X_test = pad_sequences(X_test,max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 14ms/step - loss: 0.9353 - accuracy: 0.8487\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.935344934463501, 0.8486589789390564]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=-1)\n",
    "\n",
    "# y_test = y_test.flatten()\n",
    "# y_pred = y_pred.flatten()\n",
    "\n",
    "print(y_test.shape, y_pred.shape)\n",
    "\n",
    "\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i want to order two medium pizzas with sausage and black olives and two medium pizzas with pepperoni and extra cheese and three large pizzas with pepperoni and sausage\n",
      "i want to order two medium pizza with sausage and black olive and two medium pizza with pepperoni and extra cheese and three large pizza with pepperoni and sausage\n"
     ]
    }
   ],
   "source": [
    "input_text = \"i want to order two medium pizzas with sausage and black olives and two medium pizzas with pepperoni and extra cheese and three large pizzas with pepperoni and sausage\"\n",
    "cleaned_text = clean_text(input_text)\n",
    "print(cleaned_text)\n",
    "lemmatized_text = lemma(cleaned_text)\n",
    "print(lemmatized_text)\n",
    "t_x, t_y = generate_training_data([lemmatized_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = max([len(x) for x in t_x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 77ms/step\n"
     ]
    }
   ],
   "source": [
    "t_x = input_tokinezer.texts_to_sequences(t_x)\n",
    "t_x = pad_sequences(t_x,max_len, padding='post')\n",
    "t_y = [y.split() for y in t_y]\n",
    "t_y = [[tags.index(tag) for tag in y] for y in t_y]\n",
    "t_y = pad_sequences(t_y,max_len, padding='post')\n",
    "\n",
    "pred = model.predict(t_x)\n",
    "pred = np.argmax(pred, axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sentence: i want <OOV> <OOV> two medium pizza with sausage and black olive and two medium pizza with pepperoni and extra cheese and three large pizza with pepperoni and sausage\n",
      "Predicted Tags: ['O', 'O', 'B-NUMBER', 'B-TOPPING', 'B-NUMBER', 'B-SIZE', 'O', 'O', 'B-TOPPING', 'O', 'B-TOPPING', 'I-TOPPING', 'O', 'B-NUMBER', 'B-SIZE', 'O', 'O', 'B-TOPPING', 'O', 'B-QUANTITY', 'B-TOPPING', 'O', 'B-NUMBER', 'B-SIZE', 'O', 'O', 'B-TOPPING', 'O', 'B-TOPPING', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "True Tags     : ['O', 'O', 'O', 'O', 'B-NUMBER', 'B-SIZE', 'O', 'O', 'B-TOPPING', 'O', 'B-TOPPING', 'I-TOPPING', 'O', 'B-NUMBER', 'B-SIZE', 'O', 'O', 'B-TOPPING', 'O', 'B-QUANTITY', 'B-TOPPING', 'O', 'B-NUMBER', 'B-SIZE', 'O', 'O', 'B-TOPPING', 'O', 'B-TOPPING', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert the predicted indices back to tags\n",
    "pred_tags = [[tags[idx] for idx in sentence] for sentence in pred]\n",
    "true_tags = [[tags[idx] for idx in sentence] for sentence in t_y]\n",
    "\n",
    "# Print the original sentence and the tags\n",
    "for i in range(len(t_x)):\n",
    "    original_sentence = [input_tokinezer.index_word[idx] for idx in t_x[i] if idx != 0]\n",
    "    print(\"Original Sentence:\", \" \".join(original_sentence))\n",
    "    print(\"Predicted Tags:\", pred_tags[i])\n",
    "    print(\"True Tags     :\", true_tags[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred\n",
    "df_dev['dev.INPUT'] = [[tags[idx] for idx in sentence] for sentence in y_pred]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# Example tokenized input with corresponding labels\n",
    "# tokens = [\"balsamic\", \"glaze\", \"and\", \"a\", \"sprite\", \"and\", \"three\", \"eight\", \"ounce\", \"fantas\", \"and\", \"three\", \"sprite\"]\n",
    "# labels = [\"B-TOPPING\", \"I-TOPPING\", \"O\", \"O\", \"B-DRINKTYPE\", \"O\", \"B-NUMBER\", \"B-VOLUME\", \"I-VOLUME\", \"B-DRINKTYPE\", \"O\", \"B-NUMBER\", \"B-DRINKTYPE\"]\n",
    "\n",
    "tokens = X_train[:2]\n",
    "labels = y_train[:2]\n",
    "\n",
    "# Extracting simple features for each token (you can add more sophisticated features)\n",
    "features = []\n",
    "for i in range(len(tokens)):\n",
    "    t = tokens[i].split()\n",
    "    for idx,word in enumerate(t):\n",
    "        features.append({\n",
    "            'word': word,\n",
    "            'prev_word': t[idx-1] if idx > 0 else 'SOS',\n",
    "            'next_word': t[idx+1] if idx < len(t)-1 else 'EOS',\n",
    "            'is_digit': True if  (word.isdigit() or words_to_number(word)) else False,\n",
    "        })\n",
    "    \n",
    "\n",
    "# Convert features to a feature matrix using DictVectorizer\n",
    "vectorizer = DictVectorizer(sparse=False)\n",
    "X = vectorizer.fit_transform(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 1. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a decision tree classifier\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X, labels)\n",
    "\n",
    "# Predict the labels for the tokens\n",
    "predictions = clf.predict(X)\n",
    "\n",
    "# Post-process to structure the output (as per your desired format)\n",
    "for token, label, prediction in zip(tokens, labels, predictions):\n",
    "    print(f\"Token: {token}, True Label: {label}, Predicted Label: {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_addons.text import crf_log_likelihood, viterbi_decode\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "def crf_loss(y_true, y_pred):\n",
    "    # Convert inputs to float32\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    \n",
    "    # Reshape y_pred to 3D\n",
    "    num_tags = len(extractor.tags)\n",
    "    y_pred = tf.reshape(y_pred, [-1, y_true.shape[1], num_tags])\n",
    "    \n",
    "    # Compute sequence lengths\n",
    "    sequence_lengths = tf.reduce_sum(tf.cast(tf.not_equal(y_true, 0), tf.int32), axis=1)\n",
    "    \n",
    "    # Compute log likelihood\n",
    "    log_likelihood, _ = tfa.text.crf_log_likelihood(\n",
    "        y_pred,\n",
    "        tf.cast(y_true, tf.int32),\n",
    "        sequence_lengths\n",
    "    )\n",
    "    \n",
    "    return -tf.reduce_mean(log_likelihood)\n",
    "\n",
    "\n",
    "\n",
    "def crf_accuracy(y_true, y_pred):\n",
    "    sequence_lengths = tf.reduce_sum(tf.cast(tf.not_equal(y_true, 0), tf.int32), axis=1)\n",
    "    viterbi_sequences, _ = tfa.text.viterbi_decode(y_pred, sequence_lengths)\n",
    "    correct_predictions = tf.equal(tf.cast(y_true, tf.int32), tf.cast(viterbi_sequences, tf.int32))\n",
    "    return tf.reduce_mean(tf.cast(correct_predictions, tf.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow_addons.layers import CRF\n",
    "from tensorflow_addons.text.crf import crf_decode , crf_log_likelihood ,  viterbi_decode , crf_sequence_score\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "class OrderExtractor:\n",
    "    def __init__(self, max_length=100):\n",
    "        self.max_length = max_length\n",
    "        self.word_tokenizer = Tokenizer(lower=True, split=' ')\n",
    "        \n",
    "        # Define tags for NER\n",
    "        self.tags = [\n",
    "            'O',  # Outside\n",
    "            'B-DRINKORDER', 'I-DRINKORDER',\n",
    "            'B-PIZZAORDER', 'I-PIZZAORDER',\n",
    "            'B-NUMBER', 'I-NUMBER',\n",
    "            'B-DRINKTYPE', 'I-DRINKTYPE',\n",
    "            'B-VOLUME', 'I-VOLUME',\n",
    "            'B-TOPPING', 'I-TOPPING',\n",
    "            'B-SIZE', 'I-SIZE',\n",
    "            'B-QUANTITY', 'I-QUANTITY',\n",
    "            'B-STYLE', 'I-STYLE',\n",
    "            'B-CONTAINER', 'I-CONTAINER',\n",
    "            'B-NOT-TOPPING', 'I-NOT-TOPPING',\n",
    "            'B-NOT-STYLE' , 'I-NOT-STYLE'\n",
    "        ]\n",
    "        self.tag_to_index = {tag: idx for idx, tag in enumerate(self.tags)}\n",
    "        self.index_to_tag = {idx: tag for tag, idx in self.tag_to_index.items()}\n",
    "        \n",
    "    def prepare_data(self, texts, labels):\n",
    "        # Tokenize words\n",
    "        self.word_tokenizer.fit_on_texts(texts)\n",
    "        word_sequences = self.word_tokenizer.texts_to_sequences(texts)\n",
    "        word_sequences = pad_sequences(word_sequences, maxlen=self.max_length, padding='post')\n",
    "        \n",
    "        # Prepare label sequences\n",
    "        label_sequences = []\n",
    "        for label_sequence in labels:\n",
    "            label_sequence = label_sequence.split()\n",
    "            label_sequence = [self.tag_to_index[label] for label in label_sequence]\n",
    "            label_sequences.append(label_sequence)\n",
    "            \n",
    "        label_sequences = pad_sequences(label_sequences, maxlen=self.max_length, padding='post')\n",
    "        \n",
    "        return word_sequences, label_sequences\n",
    "    \n",
    "    def create_model(self, vocab_size, embedding_dim=100, lstm_units=128):\n",
    "        # Input layer\n",
    "        input_layer = Input(shape=(self.max_length,))\n",
    "        \n",
    "        # Embedding layer\n",
    "        embedding = Embedding(\n",
    "            input_dim=vocab_size, \n",
    "            output_dim=embedding_dim, \n",
    "            mask_zero=True\n",
    "        )(input_layer)\n",
    "        \n",
    "        # BiLSTM layers with dropout\n",
    "        bilstm = Bidirectional(LSTM(\n",
    "            units=lstm_units, \n",
    "            return_sequences=True,\n",
    "            recurrent_dropout=0.2\n",
    "        ))(embedding)\n",
    "        \n",
    "        # Dense layer\n",
    "        dense = Dense(len(self.tags))(bilstm)        \n",
    "        # CRF layer\n",
    "        crf = CRF(len(self.tags),)\n",
    "        \n",
    "        output = crf(dense)\n",
    "        \n",
    "        # Create model\n",
    "        model = Model(inputs=input_layer, outputs=output)\n",
    "        model.compile(\n",
    "            optimizer='adam', \n",
    "            loss=crf_loss,\n",
    "            metrics=[crf_accuracy]\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def parse_prediction(self, tokens, prediction):\n",
    "        def extract_entity(start, entity_type):\n",
    "            entity_tokens = []\n",
    "            for j in range(start, len(tokens)):\n",
    "                if prediction[j] == self.tag_to_index[f'I-{entity_type}']:\n",
    "                    entity_tokens.append(tokens[j])\n",
    "                else:\n",
    "                    break\n",
    "            return ' '.join(entity_tokens)\n",
    "        \n",
    "        parsed_orders = []\n",
    "        current_order = {}\n",
    "        \n",
    "        for i, tag_index in enumerate(prediction):\n",
    "            tag = self.index_to_tag[tag_index]\n",
    "            \n",
    "            if tag.startswith('B-DRINKORDER') or tag.startswith('B-PIZZAORDER'):\n",
    "                if current_order:\n",
    "                    parsed_orders.append(current_order)\n",
    "                current_order = {}\n",
    "                current_order['type'] = tag.split('-')[1]\n",
    "            \n",
    "            if tag.startswith('B-NUMBER'):\n",
    "                current_order['NUMBER'] = extract_entity(i, 'NUMBER')\n",
    "            \n",
    "            if tag.startswith('B-DRINKTYPE'):\n",
    "                current_order['DRINKTYPE'] = extract_entity(i, 'DRINKTYPE')\n",
    "            \n",
    "            if tag.startswith('B-VOLUME'):\n",
    "                current_order['VOLUME'] = extract_entity(i, 'VOLUME')\n",
    "            \n",
    "            if tag.startswith('B-TOPPING'):\n",
    "                current_order['TOPPING'] = extract_entity(i, 'TOPPING')\n",
    "        \n",
    "        if current_order:\n",
    "            parsed_orders.append(current_order)\n",
    "        \n",
    "        return parsed_orders\n",
    "    \n",
    "    def format_output(self, parsed_orders):\n",
    "        output_str = \"(\"\n",
    "        for order in parsed_orders:\n",
    "            order_type = order.get('type', '')\n",
    "            output_str += f\"{order_type} \"\n",
    "            \n",
    "            if 'NUMBER' in order:\n",
    "                output_str += f\"(NUMBER {order['NUMBER']}) \"\n",
    "            \n",
    "            if 'DRINKTYPE' in order:\n",
    "                output_str += f\"(DRINKTYPE {order['DRINKTYPE'].upper()}) \"\n",
    "            \n",
    "            if 'VOLUME' in order:\n",
    "                output_str += f\"(VOLUME {order['VOLUME'].upper()}) \"\n",
    "            \n",
    "            if 'TOPPING' in order:\n",
    "                output_str += f\"(TOPPING {order['TOPPING'].upper()}) \"\n",
    "        \n",
    "        output_str += \")\"\n",
    "        return output_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example usage\n",
    "extractor = OrderExtractor()\n",
    "\n",
    "# Prepare data\n",
    "X_train_pre, y_train_pre = extractor.prepare_data(X_train, y_train)\n",
    "y_train_pre_3d = tf.keras.utils.to_categorical(y_train_pre, num_classes=len(extractor.tags))\n",
    "# Ensure labels are integer-encoded\n",
    "y_train_pre_3d = y_train_pre_3d.astype(np.int32)\n",
    "# Instead of to_categorical, keep labels as integer indices\n",
    "y_train_pre_3d = y_train_pre  # Assuming y_train_pre is already integer-encoded\n",
    "\n",
    "# Ensure labels are padded to max_length if needed\n",
    "y_train_pre_3d = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    y_train_pre_3d, \n",
    "    maxlen=extractor.max_length, \n",
    "    padding='post', \n",
    "    value=0  # Use 0 as padding value\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\Yara\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1377, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Yara\\AppData\\Local\\Temp\\ipykernel_22988\\4180131057.py\", line 15, in crf_loss  *\n        y_pred = tf.reshape(y_pred, [-1, y_true.shape[1], num_tags])\n\n    ValueError: Dimension size must be evenly divisible by 2500 but is 625 for '{{node crf_loss_3/Reshape}} = Reshape[T=DT_FLOAT, Tshape=DT_INT32](crf_loss_3/Reshape/ReadVariableOp, crf_loss_3/Reshape/shape)' with input shapes: [25,25], [3] and with input tensors computed as partial shapes: input[1] = [?,100,25].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[216], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m extractor\u001b[38;5;241m.\u001b[39mcreate_model(vocab_size)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_pre\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_pre_3d\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Predict\u001b[39;00m\n\u001b[0;32m      9\u001b[0m test_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalsamic glaze and a sprite and three eight ounce fantas and three sprites\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Yara\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileni2mgoy9.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filefq7_2h3n.py:13\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__crf_loss\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     11\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mcast, (ag__\u001b[38;5;241m.\u001b[39mld(y_pred), ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mfloat32), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     12\u001b[0m num_tags \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mlen\u001b[39m), (ag__\u001b[38;5;241m.\u001b[39mld(extractor)\u001b[38;5;241m.\u001b[39mtags,), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m---> 13\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_tags\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m sequence_lengths \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mreduce_sum, (ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mcast, (ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mnot_equal, (ag__\u001b[38;5;241m.\u001b[39mld(y_true), \u001b[38;5;241m0\u001b[39m), \u001b[38;5;28;01mNone\u001b[39;00m, fscope), ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mint32), \u001b[38;5;28;01mNone\u001b[39;00m, fscope),), \u001b[38;5;28mdict\u001b[39m(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), fscope)\n\u001b[0;32m     15\u001b[0m log_likelihood, _ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tfa)\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mcrf_log_likelihood, (ag__\u001b[38;5;241m.\u001b[39mld(y_pred), ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mcast, (ag__\u001b[38;5;241m.\u001b[39mld(y_true), ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mint32), \u001b[38;5;28;01mNone\u001b[39;00m, fscope), ag__\u001b[38;5;241m.\u001b[39mld(sequence_lengths)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\Yara\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1377, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Yara\\AppData\\Local\\Temp\\ipykernel_22988\\4180131057.py\", line 15, in crf_loss  *\n        y_pred = tf.reshape(y_pred, [-1, y_true.shape[1], num_tags])\n\n    ValueError: Dimension size must be evenly divisible by 2500 but is 625 for '{{node crf_loss_3/Reshape}} = Reshape[T=DT_FLOAT, Tshape=DT_INT32](crf_loss_3/Reshape/ReadVariableOp, crf_loss_3/Reshape/shape)' with input shapes: [25,25], [3] and with input tensors computed as partial shapes: input[1] = [?,100,25].\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "vocab_size = len(extractor.word_tokenizer.word_index) + 1\n",
    "model = extractor.create_model(vocab_size)\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train_pre, y_train_pre_3d, epochs=10, verbose=2, batch_size=32)\n",
    "\n",
    "# Predict\n",
    "test_text = \"balsamic glaze and a sprite and three eight ounce fantas and three sprites\"\n",
    "test_seq = extractor.word_tokenizer.texts_to_sequences([test_text])\n",
    "test_seq = pad_sequences(test_seq, maxlen=extractor.max_length, padding='post')\n",
    "\n",
    "prediction = model.predict(test_seq)[0]\n",
    "predicted_tags = np.argmax(prediction, axis=-1)\n",
    "\n",
    "# Parse and format output\n",
    "parsed_orders = extractor.parse_prediction(test_text.split(), predicted_tags)\n",
    "output = extractor.format_output(parsed_orders)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(sentence):\n",
    "    \"\"\"Extract features for each word in the sentence, considering context.\"\"\"\n",
    "    features = []\n",
    "    for i, word in enumerate(sentence):\n",
    "        word_features = {\n",
    "            \"word\": word,\n",
    "            \"is_digit\": word.isdigit() or words_to_number(word) is not None,\n",
    "            # \"is_title\": word.istitle(),\n",
    "            \"suffix\": word[-3:],  # Last 3 characters\n",
    "            \"prefix\": word[:3],  # First 3 characters\n",
    "        }\n",
    "        # Add previous word features\n",
    "        if i > 0:\n",
    "            word_features[\"prev_word\"] = sentence[i - 1]\n",
    "            word_features[\"prev_is_digit\"] = sentence[i - 1].isdigit()\n",
    "        else:\n",
    "            word_features[\"prev_word\"] = \"<SOS>\"\n",
    "            word_features[\"prev_is_digit\"] = False\n",
    "        \n",
    "        # Add next word features\n",
    "        if i < len(sentence) - 1:\n",
    "            word_features[\"next_word\"] = sentence[i + 1]\n",
    "            word_features[\"next_is_digit\"] = sentence[i + 1].isdigit() or words_to_number(sentence[i + 1]) is not None\n",
    "        else:\n",
    "            word_features[\"next_word\"] = \"<EOS>\"\n",
    "            word_features[\"next_is_digit\"] = False\n",
    "        \n",
    "        features.append(word_features)\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'word': \"I'd\", 'is_digit': False, 'suffix': \"I'd\", 'prefix': \"I'd\", 'prev_word': '<SOS>', 'prev_is_digit': False, 'next_word': 'like', 'next_is_digit': False}\n",
      "{'word': 'like', 'is_digit': False, 'suffix': 'ike', 'prefix': 'lik', 'prev_word': \"I'd\", 'prev_is_digit': False, 'next_word': 'three', 'next_is_digit': True}\n",
      "{'word': 'three', 'is_digit': True, 'suffix': 'ree', 'prefix': 'thr', 'prev_word': 'like', 'prev_is_digit': False, 'next_word': 'large', 'next_is_digit': False}\n",
      "{'word': 'large', 'is_digit': False, 'suffix': 'rge', 'prefix': 'lar', 'prev_word': 'three', 'prev_is_digit': False, 'next_word': 'pies', 'next_is_digit': False}\n",
      "{'word': 'pies', 'is_digit': False, 'suffix': 'ies', 'prefix': 'pie', 'prev_word': 'large', 'prev_is_digit': False, 'next_word': 'with', 'next_is_digit': False}\n",
      "{'word': 'with', 'is_digit': False, 'suffix': 'ith', 'prefix': 'wit', 'prev_word': 'pies', 'prev_is_digit': False, 'next_word': 'pesto', 'next_is_digit': False}\n",
      "{'word': 'pesto', 'is_digit': False, 'suffix': 'sto', 'prefix': 'pes', 'prev_word': 'with', 'prev_is_digit': False, 'next_word': '<EOS>', 'next_is_digit': False}\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "sentence = [\"I'd\", \"like\", \"three\", \"large\", \"pies\", \"with\", \"pesto\"]\n",
    "features = extract_features(sentence)\n",
    "for word_feature in features:\n",
    "    print(word_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Bidirectional, Dense, Concatenate, Dropout\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "# Define parameters\n",
    "vocab_size = 5000  # Vocabulary size\n",
    "pos_vocab_size = 50  # POS tags vocabulary size\n",
    "tag_size = 10  # Number of output tags\n",
    "embedding_dim = 100\n",
    "pos_embedding_dim = 16\n",
    "hidden_dim = 128\n",
    "max_len = 50  # Maximum sentence length\n",
    "\n",
    "# Word input and embedding\n",
    "word_input = Input(shape=(max_len,), dtype='int32', name='word_input')\n",
    "word_embedding = Embedding(input_dim=vocab_size, output_dim=embedding_dim, mask_zero=True, name='word_embedding')(word_input)\n",
    "\n",
    "# POS input and embedding (optional contextual feature)\n",
    "pos_input = Input(shape=(max_len,), dtype='int32', name='pos_input')\n",
    "pos_embedding = Embedding(input_dim=pos_vocab_size, output_dim=pos_embedding_dim, mask_zero=True, name='pos_embedding')(pos_input)\n",
    "\n",
    "# Combine word and POS embeddings\n",
    "combined_embedding = Concatenate(name='combined_embedding')([word_embedding, pos_embedding])\n",
    "\n",
    "# BiLSTM layer\n",
    "bilstm = Bidirectional(LSTM(hidden_dim // 2, return_sequences=True, dropout=0.1, recurrent_dropout=0.1), name='bilstm')(combined_embedding)\n",
    "\n",
    "# Dense layer to project LSTM output to tag space\n",
    "dense = Dense(tag_size, activation=None, name='dense')(bilstm)\n",
    "\n",
    "# CRF layer\n",
    "crf = tfa.layers.CRF(tag_size, name='crf')\n",
    "output = crf(dense)\n",
    "\n",
    "# Define the model\n",
    "model = Model(inputs=[word_input, pos_input], outputs=output)\n",
    "\n",
    "# Compile the model with CRF loss and accuracy\n",
    "model.compile(optimizer='adam', loss=crf.loss, metrics=[crf.metrics])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_crfsuite import CRF\n",
    "\n",
    "# Define training data\n",
    "X_train = [extract_features(sentence) for sentence in training_sentences]  # List of feature dictionaries\n",
    "y_train = training_labels  # Corresponding labels\n",
    "\n",
    "# Train CRF\n",
    "crf = CRF(algorithm='lbfgs', max_iterations=100)\n",
    "crf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_crfsuite import CRF\n",
    "\n",
    "# Define features\n",
    "def extract_features(sentence):\n",
    "    return [\n",
    "        {\n",
    "            'word': word,\n",
    "            'is_digit': word.isdigit(),\n",
    "            'is_title': word.istitle(),\n",
    "            'suffix': word[-3:],\n",
    "        }\n",
    "        for word in sentence\n",
    "    ]\n",
    "\n",
    "# Train a CRF model (pseudo-code; requires labeled dataset)\n",
    "crf = CRF(algorithm='lbfgs', max_iterations=100)\n",
    "crf.fit(X_train, train_y)  # `X_train` and `train_y` are tokenized sentences and labels\n",
    "\n",
    "# Predict on input text\n",
    "sentence = \"I'd like three large pies with pestos and yellow peppers\".split()\n",
    "features = extract_features(sentence)\n",
    "labels = crf.predict_single(features)\n",
    "\n",
    "# Map labels to the desired output\n",
    "def format_output(sentence, labels):\n",
    "    output = \"(ORDER (PIZZAORDER \"\n",
    "    for word, label in zip(sentence, labels):\n",
    "        if label == \"B-NUMBER\":\n",
    "            output += f\"(NUMBER {word} ) \"\n",
    "        elif label == \"B-SIZE\":\n",
    "            output += f\"(SIZE {word.upper()} ) \"\n",
    "        elif label.startswith(\"B-TOPPING\"):\n",
    "            output += f\"(TOPPING {word.replace(' ', '_').upper()} ) \"\n",
    "    output += \"))\"\n",
    "    return output\n",
    "\n",
    "output = format_output(sentence, labels)\n",
    "print(output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
