{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow import keras\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model,Sequential,model_from_json\n",
    "from tensorflow.keras.layers import Embedding,LSTM,Dense,Input,Bidirectional,Dropout,Convolution1D,GRU,TimeDistributed\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "MAX_LEN = 45\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTRACTIONS = {\n",
    "    \"n't\": \"not\",\n",
    "    \"'s\": \"is\",\n",
    "    \"'re\": \"are\",\n",
    "    \"'m\": \"am\",\n",
    "    \"'ll\": \"will\",\n",
    "    \"'ve\": \"have\",\n",
    "    \"'d\": \"would\",\n",
    "    \"'em\": \"them\",\n",
    "    \"'all\": \"all\",\n",
    "    \"'cause\": \"because\",\n",
    "    \"'clock\": \"oclock\",\n",
    "    \"'tis\": \"it is\",\n",
    "    \"'twas\": \"it was\",\n",
    "    \"'tween\": \"between\",\n",
    "    \"'twere\": \"it were\",\n",
    "    \"'twould\": \"it would\",\n",
    "    \"'twixt\": \"betwixt\",\n",
    "    \"'twill\": \"it will\",\n",
    "    \"'til\": \"until\",\n",
    "    \"'bout\": \"about\",\n",
    "    \"'cept\": \"except\",\n",
    "    \"'cos\": \"because\",\n",
    "    \"'fore\": \"before\",\n",
    "    \"'round\": \"around\",\n",
    "    \"'n'\": \"and\",\n",
    "    \"'neath\": \"beneath\",\n",
    "    \"'nother\": \"another\",\n",
    "    \"'nuff\": \"enough\",\n",
    "}\n",
    "negation_words = {\n",
    "    \"no\",\n",
    "    \"not\",\n",
    "    \"none\",\n",
    "    \"never\",\n",
    "    \"without\",\n",
    "    \"avoid\",\n",
    "    \"neither\",\n",
    "    \"nor\",\n",
    "    \"hate\",\n",
    "    \"hold\",\n",
    "}\n",
    "pizza = {\"pizza\", \"pizzas\", \"pie\", \"pies\"}\n",
    "\n",
    "stop_negation_words = {\"and\"}\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "stop_words = stop_words - negation_words - stop_negation_words - {'all' , 'a','an' , 'can'}\n",
    "stop_words.update({\"would\", \"like\", \"get\", \"want\", \"order\" , \"please\" , 'could' , 'prefer' ,\n",
    "                    'handle' , 'take' , 'bring' , 'need' , 'make' , 'love', 'let', 'absolutely',\n",
    "                    \"arrange\",'today' , 'tommorow','add' , 'thank' , 'thanks' , 'tonight' , 'right' , 'left'})\n",
    "stop_words.update(pizza)\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()  # WordNet Lemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expnad_abb2(text):\n",
    "\n",
    "    pattern = re.compile(\n",
    "        r\"(\" + \"|\".join(re.escape(key) for key in CONTRACTIONS.keys()) + r\")\"\n",
    "    )\n",
    "    expanded_text = pattern.sub(lambda x: \" \" + CONTRACTIONS[x.group()], text)\n",
    "    return expanded_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return \" \".join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r\"[^\\w']\", \" \", text)  # Remove non-word characters\n",
    "    text = re.sub(r\"\\s+\", \" \", text)  # Remove multiple spaces\n",
    "    text = text.lower().strip()  # Lowercase and strip whitespace\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "relation_tags = {\n",
    "    'O':0,\n",
    "    'B-Pizza':1, 'I-Pizza':2,\n",
    "    'B-Drink':3, 'I-Drink':4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = [\n",
    "    'O',\n",
    "    'B-NUMBER', 'I-NUMBER',\n",
    "    'B-DRINKTYPE', 'I-DRINKTYPE',\n",
    "    'B-VOLUME', 'I-VOLUME',\n",
    "    'B-TOPPING', 'I-TOPPING',\n",
    "    'B-SIZE', 'I-SIZE',\n",
    "    'B-QUANTITY', 'I-QUANTITY',\n",
    "    'B-STYLE', 'I-STYLE',\n",
    "    'B-CONTAINER', 'I-CONTAINER',\n",
    "    'B-NOT-TOPPING', 'I-NOT-TOPPING',\n",
    "    'B-NOT-STYLE' , 'I-NOT-STYLE'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemma(text):\n",
    "    text = text.split()\n",
    "    text = [lemmatizer.lemmatize(word) for word in text] \n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading\n",
    "with open('finalModel/tokenizer.pickle', 'rb') as handle:\n",
    "    input_tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_text_model = FastText.load(\"finalModel/fast_text_model_500k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = input_tokenizer.word_index\n",
    "\n",
    "max_length = MAX_LEN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not found <OOV>\n"
     ]
    }
   ],
   "source": [
    "# Prepare word embeddings using FastText\n",
    "embedding_dim = fast_text_model.wv.vector_size  # Dimension of Word2Vec vectors\n",
    "\n",
    "# Initialize a matrix to store word vectors\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))\n",
    "\n",
    "# Fill the embedding matrix with FastText word vectors\n",
    "for word, idx in word_index.items():\n",
    "    if word in fast_text_model.wv.key_to_index.keys():\n",
    "        # print(\"found\" , word)\n",
    "        embedding_matrix[idx] = fast_text_model.wv[word]\n",
    "    else:\n",
    "        print(\"not found\" , word)\n",
    "        embedding_matrix[idx] = np.random.uniform(-0.01, 0.01, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,920</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">193,536</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,285</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m45\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m45\u001b[0m, \u001b[38;5;34m60\u001b[0m)         │        \u001b[38;5;34m16,920\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m45\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │       \u001b[38;5;34m193,536\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m45\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m45\u001b[0m, \u001b[38;5;34m5\u001b[0m)          │         \u001b[38;5;34m1,285\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">211,741</span> (827.11 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m211,741\u001b[0m (827.11 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">194,821</span> (761.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m194,821\u001b[0m (761.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,920</span> (66.09 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m16,920\u001b[0m (66.09 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the BiLSTM model\n",
    "input = Input(shape=(max_length,))\n",
    "embedding_layer = Embedding(input_dim=len(word_index) + 1,\n",
    "                            output_dim=embedding_dim,\n",
    "                            weights=[embedding_matrix],\n",
    "                            trainable=False)(input)\n",
    "\n",
    "lstm = Bidirectional(LSTM(units=128, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))(embedding_layer)\n",
    "dropout = Dropout(0.1)(lstm)\n",
    "\n",
    "# Dense layer for sequence labeling (softmax activation)\n",
    "output = Dense(len(relation_tags), activation='softmax')(dropout)\n",
    "\n",
    "# Build and compile the model\n",
    "model_relations = Model(inputs=input, outputs=output)\n",
    "model_relations.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Model summary\n",
    "model_relations.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yara\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 18 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "model_relations.load_weights(\"finalModel/model_relations.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tokenizer2 = pickle.load(open(\"finalModel/input_tokenizer2.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">64,128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">69,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_1              │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,121</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_4 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m45\u001b[0m, \u001b[38;5;34m100\u001b[0m)          │        \u001b[38;5;34m24,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m45\u001b[0m, \u001b[38;5;34m128\u001b[0m)          │        \u001b[38;5;34m64,128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m45\u001b[0m, \u001b[38;5;34m128\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_1 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m45\u001b[0m, \u001b[38;5;34m100\u001b[0m)          │        \u001b[38;5;34m69,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_1              │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m45\u001b[0m, \u001b[38;5;34m21\u001b[0m)           │         \u001b[38;5;34m2,121\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">318,700</span> (1.22 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m318,700\u001b[0m (1.22 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">159,349</span> (622.46 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m159,349\u001b[0m (622.46 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">159,351</span> (622.47 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m159,351\u001b[0m (622.47 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "json_file = open('finalModel/model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model_entity = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "model_entity.load_weights(\"finalModel/model.weights.h5\")\n",
    "model_entity.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setToppings(token, tokens, i,entity_preds):\n",
    "    quantity = None\n",
    "    temp = \"\"\n",
    "    not_flag = False\n",
    "    while(\"TOPPING\" in entity_preds[i] or \"QUANTITY\" in entity_preds[i]):\n",
    "        if \"NOT\" in entity_preds[i]:\n",
    "            not_flag = True\n",
    "            temp += \" \" + tokens[i]\n",
    "        elif \"QUANTITY\" in entity_preds[i]:\n",
    "            quantity = tokens[i]\n",
    "        else :\n",
    "            temp += \" \"  + tokens[i]\n",
    "        i+=1\n",
    "        \n",
    "    if temp == \"\":\n",
    "        topping = None\n",
    "    \n",
    "    else : \n",
    "        topping = {\n",
    "        \"NOT\": not_flag,\n",
    "        \"Quantity\": quantity,\n",
    "        \"Topping\": temp\n",
    "    }\n",
    "    return topping,i-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setStyle (token, tokens, i,entity_preds):\n",
    "    temp = \"\"\n",
    "    not_flag = False\n",
    "    while(\"STYLE\" in entity_preds[i]):\n",
    "        if \"NOT\" in entity_preds[i]:\n",
    "            not_flag = True\n",
    "            temp += \" \" + tokens[i]\n",
    "        else:\n",
    "            temp += \" \"  + tokens[i]\n",
    "        i+=1\n",
    "\n",
    "    style = {\n",
    "        \"NOT\": not_flag,\n",
    "        \"TYPE\": temp\n",
    "    }\n",
    "    return style,i-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pizza_order(relations_preds,tokens,entity_preds,i):\n",
    "    current_order = {\"NUMBER\": None, \"SIZE\": None, \"STYLE\": [], \"AllTopping\": []}\n",
    "    temp_i = i\n",
    "    while(i < len(tokens) and (temp_i == i or relations_preds[i] == 'I-Pizza' or relations_preds[i] == 'O' )):\n",
    "        if entity_preds[i] == \"B-TOPPING\" or entity_preds[i] == \"B-NOT-TOPPING\" or (entity_preds[i] == \"B-QUANTITY\" and i+1 < len(entity_preds) and entity_preds[i+1] == \"B-TOPPING\"):\n",
    "            topping,i= setToppings(tokens[i], tokens, i,entity_preds )\n",
    "            if topping is not None:\n",
    "                current_order[\"AllTopping\"].append(topping)\n",
    "\n",
    "        elif entity_preds[i] == \"B-NUMBER\":\n",
    "            current_order[\"NUMBER\"] = tokens[i]\n",
    "        elif entity_preds[i] == \"B-SIZE\":\n",
    "            if entity_preds[i-1] == \"B-QUANTITY\":\n",
    "                current_order[\"SIZE\"] = tokens[i-1] + \" \" + tokens[i]\n",
    "            else:\n",
    "                current_order[\"SIZE\"] = tokens[i]\n",
    "        \n",
    "        elif \"STYLE\" in entity_preds[i]:\n",
    "            s,i = setStyle(tokens[i], tokens, i,entity_preds)\n",
    "            current_order[\"STYLE\"].append(s)\n",
    "        i += 1\n",
    "    return current_order,i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setDrink(token, tokens, i,entity_preds):\n",
    "    temp = \"\"\n",
    "    while(token in entity_preds[i]):\n",
    "        temp += \" \"  + tokens[i]\n",
    "        i+=1\n",
    "    return temp,i-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_drink_order(relations_preds,tokens,entity_preds,i):\n",
    "    current_order = {\"NUMBER\": None, \"DRINKTYPE\": None, \"VOLUME\": None, \"CONTAINER\": None,\"SIZE\": None}\n",
    "    temp_i = i\n",
    "    while( i < len(tokens) and (temp_i == i or relations_preds[i] == 'I-Drink' or relations_preds[i] == 'O')):\n",
    "        # if \"B-DRINKTYPE\" in entity_preds[i]:\n",
    "            # current_order[\"DRINKTYPE\"],i = setDrink(\"DRINKTYPE\", tokens, i,entity_preds)\n",
    "        if entity_preds[i] == \"B-NUMBER\":\n",
    "            current_order[\"NUMBER\"] = tokens[i]\n",
    "        elif \"VOLUME\" in entity_preds[i]:\n",
    "            current_order[\"VOLUME\"],i = setDrink(\"VOLUME\", tokens, i,entity_preds)\n",
    "        elif \"CONTAINER\" in entity_preds[i]:\n",
    "            current_order[\"CONTAINER\"],i = setDrink(\"CONTAINER\" , tokens, i,entity_preds)\n",
    "        elif \"SIZE\" in entity_preds[i]:\n",
    "            current_order[\"SIZE\"],i = setDrink(\"SIZE\" , tokens, i,entity_preds)\n",
    "        elif entity_preds[i] != 'O': \n",
    "            current_order[\"DRINKTYPE\"] = tokens[i]\n",
    "\n",
    "        i += 1\n",
    "    return current_order,i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_order(input_text, relations_preds, entity_preds):\n",
    "    tokens = input_text.split()\n",
    "\n",
    "    # Combine predictions with tokens\n",
    "    combined = [\n",
    "        {\"token\": token, \"model1\": m1, \"model2\": m2}\n",
    "        for token, m1, m2 in zip(tokens, relations_preds, entity_preds)\n",
    "    ]\n",
    "\n",
    "    pizza_orders = []\n",
    "    drink_orders = []\n",
    "    current_order = None\n",
    "\n",
    "    for i, item in enumerate(combined):\n",
    "        token, model1, model2 = item[\"token\"], item[\"model1\"], item[\"model2\"]\n",
    "\n",
    "        if model1 == \"B-Pizza\":\n",
    "            # Start a new order\n",
    "            current_order , i = get_pizza_order(relations_preds,tokens,entity_preds,i)\n",
    "            if len(current_order[\"AllTopping\"]) == 0 and current_order[\"SIZE\"] is None and current_order[\"NUMBER\"] is None and len(current_order[\"STYLE\"]) == 0:\n",
    "                continue\n",
    "            if current_order[\"NUMBER\"] is None:\n",
    "                current_order[\"NUMBER\"] = \"a\"\n",
    "            pizza_orders.append(current_order)\n",
    "\n",
    "\n",
    "        elif model1 == \"B-Drink\":\n",
    "            current_order , i = get_drink_order(relations_preds,tokens,entity_preds,i)\n",
    "            drink_orders.append(current_order)\n",
    "\n",
    "        elif model1 == \"I-Pizza\" and current_order is None: \n",
    "            current_order , i = get_pizza_order(relations_preds,tokens,entity_preds,i)\n",
    "            if len(current_order[\"AllTopping\"]) == 0 and current_order[\"SIZE\"] is None and current_order[\"NUMBER\"] is None and len(current_order[\"STYLE\"]) == 0:\n",
    "                continue\n",
    "            if current_order[\"NUMBER\"] is None:\n",
    "                current_order[\"NUMBER\"] = \"a\"\n",
    "            pizza_orders.append(current_order)\n",
    "\n",
    "\n",
    "\n",
    "    # Construct final output\n",
    "    output = {\"ORDER\": {\"PIZZAORDER\": pizza_orders, \"DRINKORDER\": drink_orders}}\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence = \"could you give me a exta large pizza without roasted red peppers and more cheese but no sausage\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After preprocessing:  give a exta large without roasted red pepper and cheese no sausage\n"
     ]
    }
   ],
   "source": [
    "test_sentence = clean_text(test_sentence)\n",
    "test_sentence = expnad_abb2(test_sentence)\n",
    "test_sentence = remove_stopwords(test_sentence)\n",
    "test_sentence = lemma(test_sentence)\n",
    "\n",
    "print(\"After preprocessing: \", test_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After tokenization:  [[ 1  3  1 20 18 36 37 16  2  5 12 95  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "test_sentence_seq = input_tokenizer.texts_to_sequences([test_sentence])\n",
    "test_sentence_seq = pad_sequences(test_sentence_seq, maxlen=MAX_LEN , padding='post')\n",
    "print(\"After tokenization: \", test_sentence_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "Relation prediction:  ['B-Pizza', 'O', 'O', 'I-Pizza', 'I-Pizza', 'I-Pizza', 'I-Pizza', 'I-Pizza', 'O', 'I-Pizza', 'I-Pizza', 'I-Pizza', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "pred_relation = model_relations.predict(test_sentence_seq)\n",
    "pred_relation = np.argmax(pred_relation, axis=-1)\n",
    "pred_relation = [list(relation_tags.keys())[list(relation_tags.values()).index(i)] for i in pred_relation[0]]\n",
    "print(\"Relation prediction: \", pred_relation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After tokenization:  [[ 1  3  1 21 19 37 38  7  2  5 14 86  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "test_sentence_seq = input_tokenizer2.texts_to_sequences([test_sentence])\n",
    "test_sentence_seq = pad_sequences(test_sentence_seq, maxlen=MAX_LEN , padding='post')\n",
    "print(\"After tokenization: \", test_sentence_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Entity prediction:  ['B-CONTAINER', 'B-NUMBER', 'B-STYLE', 'B-SIZE', 'O', 'B-NOT-TOPPING', 'I-NOT-TOPPING', 'B-TOPPING', 'O', 'B-TOPPING', 'O', 'B-NOT-TOPPING', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "pred_entity = model_entity.predict(test_sentence_seq)\n",
    "pred_entity = np.argmax(pred_entity, axis=-1)\n",
    "pred_entity = [tags[i] for i in pred_entity[0]]\n",
    "print(\"Entity prediction: \", pred_entity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final output: \n",
      "{\n",
      "    \"ORDER\": {\n",
      "        \"PIZZAORDER\": [\n",
      "            {\n",
      "                \"NUMBER\": \"a\",\n",
      "                \"SIZE\": \"large\",\n",
      "                \"STYLE\": [\n",
      "                    {\n",
      "                        \"NOT\": false,\n",
      "                        \"TYPE\": \" exta\"\n",
      "                    }\n",
      "                ],\n",
      "                \"AllTopping\": [\n",
      "                    {\n",
      "                        \"NOT\": true,\n",
      "                        \"Quantity\": null,\n",
      "                        \"Topping\": \" roasted red pepper\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"NOT\": false,\n",
      "                        \"Quantity\": null,\n",
      "                        \"Topping\": \" cheese\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"NOT\": true,\n",
      "                        \"Quantity\": null,\n",
      "                        \"Topping\": \" sausage\"\n",
      "                    }\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"DRINKORDER\": []\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "output = parse_order(test_sentence, pred_relation, pred_entity)\n",
    "print(\"Final output: \")\n",
    "print(json.dumps(output, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
