{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from enum import Enum\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"dataset/\"\n",
    "\n",
    "class Label(Enum):\n",
    "    TOPPING = 0\n",
    "    NUMBER = 1\n",
    "    SIZE = 2\n",
    "    QUANTITY = 3\n",
    "    STYLE = 4\n",
    "    DRINKTYPE = 5\n",
    "    CONTAINERTYPE = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_json(dataset_dir + \"PIZZA_train.json\", lines=True)\n",
    "df_dev = pd.read_json(dataset_dir + \"PIZZA_dev.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_top = df_train[\"train.TOP\"]\n",
    "train_exr = df_train[\"train.EXR\"]\n",
    "\n",
    "dev_top = df_dev[\"dev.TOP\"]\n",
    "dev_exr = df_dev[\"dev.EXR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Why dict? 1- To keep the order of the data 2- To ensure unique values\n",
    "train_data = {}\n",
    "dev_data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "toppings_regex = re.compile(r'(?<=\\(TOPPING\\s)[^)]*(?=\\s)')\n",
    "number_regex = re.compile(r'(?<=\\(NUMBER\\s)[^)]*(?=\\s)')\n",
    "size_regex = re.compile(r'(?<=\\(SIZE\\s)[^)]*(?=\\s)')\n",
    "quantity_regex = re.compile(r'(?<=\\(QUANTITY\\s)[^)]*(?=\\s)')\n",
    "style_regex = re.compile(r'(?<=\\(STYLE\\s)[^)]*(?=\\s)')\n",
    "drink_type_regex = re.compile(r'(?<=\\(DRINKTYPE\\s)[^)]*(?=\\s)')\n",
    "container_type_regex = re.compile(r'(?<=\\(CONTAINERTYPE\\s)[^)]*(?=\\s)')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_regex(regex, text):\n",
    "    match = re.findall(regex, text)\n",
    "    return match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train_top)):\n",
    "    l = apply_regex(toppings_regex, train_top.loc[i])\n",
    "    train_data.update({e : Label.TOPPING.value for e in l})\n",
    "    l = apply_regex(toppings_regex, train_exr.loc[i])\n",
    "    train_data.update({e : Label.TOPPING.value for e in l})\n",
    "    \n",
    "for i in range(len(dev_top)):\n",
    "    l = apply_regex(toppings_regex, dev_top.loc[i])\n",
    "    dev_data.update({e : Label.TOPPING.value for e in l})\n",
    "    l = apply_regex(toppings_regex, dev_exr.loc[i])\n",
    "    dev_data.update({e : Label.TOPPING.value for e in l})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train_top)):\n",
    "    l = apply_regex(number_regex, train_top.loc[i])\n",
    "    train_data.update({e : Label.NUMBER.value for e in l})\n",
    "    l = apply_regex(number_regex, train_exr.loc[i])\n",
    "    train_data.update({e : Label.NUMBER.value for e in l})\n",
    "\n",
    "for i in range(len(dev_top)):\n",
    "    l = apply_regex(number_regex, dev_top.loc[i])\n",
    "    dev_data.update({e : Label.NUMBER.value for e in l})\n",
    "    l = apply_regex(number_regex, dev_exr.loc[i])\n",
    "    dev_data.update({e : Label.NUMBER.value for e in l})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train_top)):\n",
    "    l = apply_regex(quantity_regex, train_top.loc[i])\n",
    "    train_data.update({e : Label.QUANTITY.value for e in l})\n",
    "    l = apply_regex(quantity_regex, train_exr.loc[i])\n",
    "    train_data.update({e : Label.QUANTITY.value for e in l})\n",
    "\n",
    "\n",
    "for i in range(len(dev_top)):\n",
    "    l = apply_regex(quantity_regex, dev_top.loc[i])\n",
    "    dev_data.update({e : Label.QUANTITY.value for e in l})\n",
    "    l = apply_regex(quantity_regex, dev_exr.loc[i])\n",
    "    dev_data.update({e : Label.QUANTITY.value for e in l})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train_top)):\n",
    "    l = apply_regex(size_regex, train_top.loc[i])\n",
    "    train_data.update({e : Label.SIZE.value for e in l})\n",
    "    l = apply_regex(size_regex, train_exr.loc[i])\n",
    "    train_data.update({e : Label.SIZE.value for e in l})\n",
    "\n",
    "\n",
    "for i in range(len(dev_top)):\n",
    "    l = apply_regex(size_regex, dev_top.loc[i])\n",
    "    dev_data.update({e : Label.SIZE.value for e in l})\n",
    "    l = apply_regex(size_regex, dev_exr.loc[i])\n",
    "    dev_data.update({e : Label.SIZE.value for e in l})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train_top)):\n",
    "    l = apply_regex(drink_type_regex, train_top.loc[i])\n",
    "    train_data.update({e : Label.DRINKTYPE.value for e in l})\n",
    "    l = apply_regex(drink_type_regex, train_exr.loc[i])\n",
    "    train_data.update({e : Label.DRINKTYPE.value for e in l})\n",
    "\n",
    "for i in range(len(dev_top)):\n",
    "    l = apply_regex(drink_type_regex, dev_top.loc[i])\n",
    "    dev_data.update({e : Label.DRINKTYPE.value for e in l})\n",
    "    l = apply_regex(drink_type_regex, dev_exr.loc[i])\n",
    "    dev_data.update({e : Label.DRINKTYPE.value for e in l})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train_top)):\n",
    "    l = apply_regex(style_regex, train_top.loc[i])\n",
    "    train_data.update({e : Label.STYLE.value for e in l})\n",
    "    l = apply_regex(style_regex, train_exr.loc[i])\n",
    "    train_data.update({e : Label.STYLE.value for e in l})\n",
    "\n",
    "for i in range(len(dev_top)):\n",
    "    l = apply_regex(style_regex, dev_top.loc[i])\n",
    "    dev_data.update({e : Label.STYLE.value for e in l})\n",
    "    l = apply_regex(style_regex, dev_exr.loc[i])\n",
    "    dev_data.update({e : Label.STYLE.value for e in l})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train_top)):\n",
    "    l = apply_regex(container_type_regex, train_top.loc[i])\n",
    "    train_data.update({e : Label.CONTAINERTYPE.value for e in l})\n",
    "    l = apply_regex(container_type_regex, train_exr.loc[i])\n",
    "    train_data.update({e : Label.CONTAINERTYPE.value for e in l})\n",
    "\n",
    "for i in range(len(dev_top)):\n",
    "    l = apply_regex(container_type_regex, dev_top.loc[i])\n",
    "    dev_data.update({e : Label.CONTAINERTYPE.value for e in l})\n",
    "    l = apply_regex(container_type_regex, dev_exr.loc[i])\n",
    "    dev_data.update({e : Label.CONTAINERTYPE.value for e in l})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(489, 188)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Actually it's small :))\n",
    "\n",
    "len(train_data), len(dev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_df = pd.DataFrame(train_data.items(), columns=[\"word\", \"label\"])\n",
    "dev_data_df = pd.DataFrame(dev_data.items(), columns=[\"word\", \"label\"])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_data_df[\"word\"], dev_data_df[\"word\"], train_data_df[\"label\"], dev_data_df[\"label\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.94        89\n",
      "           1       1.00      0.55      0.71        20\n",
      "           2       1.00      0.92      0.96        12\n",
      "           3       1.00      0.67      0.80         6\n",
      "           4       0.96      1.00      0.98        23\n",
      "           5       1.00      0.97      0.99        34\n",
      "           6       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           0.93       188\n",
      "   macro avg       0.98      0.87      0.91       188\n",
      "weighted avg       0.94      0.93      0.92       188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We need to balance the classes as with the current dataset the model will be biased towards the majority class --> TOPPING\n",
    "# When I tried to train the model without balancing the classes, the model was predicting only TOPPING :)\n",
    " \n",
    "classifier_lr = LogisticRegression(class_weight='balanced', random_state=42)\n",
    "\n",
    "classifier_lr.fit(X_train_tfidf, y_train)\n",
    "predictions = classifier_lr.predict(X_test_tfidf)\n",
    "print(classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99        89\n",
      "           1       0.83      1.00      0.91        20\n",
      "           2       1.00      0.92      0.96        12\n",
      "           3       1.00      0.67      0.80         6\n",
      "           4       0.96      1.00      0.98        23\n",
      "           5       1.00      0.97      0.99        34\n",
      "           6       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           0.97       188\n",
      "   macro avg       0.97      0.93      0.95       188\n",
      "weighted avg       0.98      0.97      0.97       188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier_svm = SVC(class_weight='balanced', random_state=42)\n",
    "classifier_svm.fit(X_train_tfidf, y_train)\n",
    "predictions = classifier_svm.predict(X_test_tfidf)\n",
    "print(classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99        89\n",
      "           1       0.83      1.00      0.91        20\n",
      "           2       1.00      0.92      0.96        12\n",
      "           3       1.00      0.67      0.80         6\n",
      "           4       0.96      1.00      0.98        23\n",
      "           5       1.00      0.97      0.99        34\n",
      "           6       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           0.97       188\n",
      "   macro avg       0.97      0.93      0.95       188\n",
      "weighted avg       0.98      0.97      0.97       188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier_mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=300,random_state=42)\n",
    "classifier_mlp.fit(X_train_tfidf, y_train)\n",
    "predictions = classifier_mlp.predict(X_test_tfidf)\n",
    "print(classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99        89\n",
      "           1       0.83      1.00      0.91        20\n",
      "           2       1.00      0.92      0.96        12\n",
      "           3       1.00      0.67      0.80         6\n",
      "           4       0.96      1.00      0.98        23\n",
      "           5       1.00      0.97      0.99        34\n",
      "           6       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           0.97       188\n",
      "   macro avg       0.97      0.93      0.95       188\n",
      "weighted avg       0.98      0.97      0.97       188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier_rf = RandomForestClassifier(class_weight='balanced',random_state=42)\n",
    "classifier_rf.fit(X_train_tfidf, y_train)\n",
    "predictions = classifier_rf.predict(X_test_tfidf)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NEXT STEPS ?? \n",
    "# Relationships model (What will be the input of it ?)\n",
    "\n",
    "# Use BOW instead of TFIDF in classification model? \n",
    "# Data Augmentation (I guess it's important as the dataset is small)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
