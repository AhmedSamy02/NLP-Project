{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.stem import PorterStemmer, SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import TreebankWordTokenizer, word_tokenize, MWETokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"dataset/\"\n",
    "CONTRACTIONS = {\n",
    "    \"n't\": \"not\",\n",
    "    \"'s\": \"is\",\n",
    "    \"'re\": \"are\",\n",
    "    \"'m\": \"am\",\n",
    "    \"'ll\": \"will\",\n",
    "    \"'ve\": \"have\",\n",
    "    \"'d\": \"would\",\n",
    "    \"'em\": \"them\",\n",
    "    \"'all\": \"all\",\n",
    "    \"'cause\": \"because\",\n",
    "    \"'clock\": \"oclock\",\n",
    "    \"'tis\": \"it is\",\n",
    "    \"'twas\": \"it was\",\n",
    "    \"'tween\": \"between\",\n",
    "    \"'twere\": \"it were\",\n",
    "    \"'twould\": \"it would\",\n",
    "    \"'twixt\": \"betwixt\",\n",
    "    \"'twill\": \"it will\",\n",
    "    \"'til\": \"until\",\n",
    "    \"'bout\": \"about\",\n",
    "    \"'cept\": \"except\",\n",
    "    \"'cos\": \"because\",\n",
    "    \"'fore\": \"before\",\n",
    "    \"'round\": \"around\",\n",
    "    \"'n'\": \"and\",\n",
    "    \"'neath\": \"beneath\",\n",
    "    \"'nother\": \"another\",\n",
    "    \"'nuff\": \"enough\",\n",
    "}\n",
    "negation_words = {\n",
    "    \"no\",\n",
    "    \"not\",\n",
    "    \"none\",\n",
    "    \"never\",\n",
    "    \"without\",\n",
    "    \"avoid\",\n",
    "    \"neither\",\n",
    "    \"nor\",\n",
    "    \"hate\",\n",
    "    \"hold\",\n",
    "}\n",
    "tokenizer = TreebankWordTokenizer()  # Treebank Word Tokenizer\n",
    "lemmatizer = WordNetLemmatizer()  # WordNet Lemmatizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "# tokenizer = MWETokenizer() # Multi-Word Expression Tokenizer\n",
    "stemmer = (\n",
    "    PorterStemmer()\n",
    ")  # Porter Stemmer  # changes ordering to order and cheese to chees it may help us\n",
    "# stemmer = SnowballStemmer(\"english\") # ! The same as porter stemmer\n",
    "stop_negation_words = {\"and\", \"but\"}\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "stop_words = stop_words - negation_words - stop_negation_words\n",
    "stop_words.update({\"would\", \"like\", \"get\", \"want\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Clean text from any unneeded characters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r\"[^\\w']\", \" \", text)  # Remove non-word characters\n",
    "    text = re.sub(r\"\\s+\", \" \", text)  # Remove multiple spaces\n",
    "    text = text.lower().strip()  # Lowercase and strip whitespace\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expnad_abb(text):\n",
    "    text = text.replace(\"can't\", \"can not\")\n",
    "    text = text.replace(\"won't\", \"will not\")\n",
    "    text = text.replace(\"n't\", \" not\")\n",
    "    text = text.replace(\"'ll\", \" will\")\n",
    "    text = text.replace(\"'ve\", \" have\")\n",
    "    text = text.replace(\"'re\", \" are\")\n",
    "    text = text.replace(\"'m\", \" am\")\n",
    "    text = text.replace(\"'d\", \" would\")\n",
    "    return text\n",
    "\n",
    "\n",
    "def expnad_abb2(text):\n",
    "\n",
    "    pattern = re.compile(\n",
    "        r\"(\" + \"|\".join(re.escape(key) for key in CONTRACTIONS.keys()) + r\")\"\n",
    "    )\n",
    "    expanded_text = pattern.sub(lambda x: \" \" + CONTRACTIONS[x.group()], text)\n",
    "    return expanded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return \" \".join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_negation(text):\n",
    "    # Look for patterns like \"no [word1] [word2] ...\" and transform them\n",
    "    words = text.split()\n",
    "    transformed_words = []\n",
    "    negation_flag = False  # To track if we're negating\n",
    "\n",
    "    for i, word in enumerate(words):\n",
    "        if word.lower() in negation_words:  # Trigger negation\n",
    "            negation_flag = True\n",
    "            continue  # Skip adding \"no\" to the transformed text\n",
    "        elif negation_flag and (\n",
    "            not re.match(r\"[a-zA-Z]+\", word) or word.lower() in stop_negation_words\n",
    "        ):  # End negation on punctuation or 'and'\n",
    "            negation_flag = False\n",
    "\n",
    "        # Prefix \"NOT_\" if negation flag is set\n",
    "        if negation_flag:\n",
    "            transformed_words.append(f\"NOT_{word}\")\n",
    "            if word in [\"much\"]:\n",
    "                negation_flag = False\n",
    "        else:\n",
    "            if word.lower() not in stop_negation_words:\n",
    "                transformed_words.append(word)\n",
    "\n",
    "    return \" \".join(transformed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_lemmatize(text: str):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    final_string = \"\"\n",
    "    # stemmed_tokens = []\n",
    "    for token in tokens:\n",
    "        stemmed_token = stemmer.stem(token, False) + \" \"\n",
    "        # I think this is better than lemmatization\n",
    "        final_string += stemmed_token + \" \"\n",
    "        # stemmed_tokens.append(stemmed_token)\n",
    "        # final_string += lemmatizer.lemmatize(token) + \" \"  # Didn't do anything\n",
    "    return final_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT_ordering NOT_pizza NOT_extra NOT_cheese NOT_soda NOT_organization\n"
     ]
    }
   ],
   "source": [
    "cleaned_text = handle_negation(\n",
    "    remove_stopwords(\n",
    "        expnad_abb2(\n",
    "            clean_text(\n",
    "                # \"i want a lunch size pizza with no apple wood bacon but extra cheese\" #Success\n",
    "                # \"I'll order some pizza for lunch and I don't eat spaghetti I eat Pasta WIth white sauce\" # Failed\n",
    "                # \"i didn't eat from yesterday can you please order me 2 pizzas? I don't love pepperoni What about mushroom?\" #Failed\n",
    "                \"I'm not ordering pizza with extra cheese I want Soda and I don't like your organization\"\n",
    "                # \"I need pizza with extra cheese without cucumber or tomatoes add only pepperoni 'cause I love peperoni\"  # Failed\n",
    "            )\n",
    "        )\n",
    "    )\n",
    ")\n",
    "print(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmed Tokens: NOT_order  NOT_pizza  NOT_extra  NOT_chees  NOT_soda  NOT_organ  \n"
     ]
    }
   ],
   "source": [
    "stemmed_tokens = tokenize_and_lemmatize(cleaned_text)\n",
    "# print(\"Tokens:\", tokens)\n",
    "print(\"Stemmed Tokens:\", stemmed_tokens)\n",
    "# print(\"Processed String:\", processed_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_json(dataset_dir + \"PIZZA_train.json\", lines=True)\n",
    "df_dev = pd.read_json(dataset_dir + \"PIZZA_dev.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train.SRC</th>\n",
       "      <th>train.EXR</th>\n",
       "      <th>train.TOP</th>\n",
       "      <th>train.TOP-DECOUPLED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>can i have a large bbq pulled pork</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...</td>\n",
       "      <td>(ORDER can i have (PIZZAORDER (NUMBER a ) (SIZ...</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER a ) (SIZE large ) (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>large pie with green pepper and with extra pep...</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...</td>\n",
       "      <td>(ORDER (PIZZAORDER (SIZE large ) pie with (TOP...</td>\n",
       "      <td>(ORDER (PIZZAORDER (SIZE large ) (TOPPING gree...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i'd like a large vegetarian pizza</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...</td>\n",
       "      <td>(ORDER i'd like (PIZZAORDER (NUMBER a ) (SIZE ...</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER a ) (SIZE large ) (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>party size stuffed crust pie with american che...</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 1 ) (SIZE PARTY_SIZ...</td>\n",
       "      <td>(ORDER (PIZZAORDER (SIZE party size ) (STYLE s...</td>\n",
       "      <td>(ORDER (PIZZAORDER (SIZE party size ) (STYLE s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>can i have one personal sized artichoke</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 1 ) (SIZE PERSONAL_...</td>\n",
       "      <td>(ORDER can i have (PIZZAORDER (NUMBER one ) (S...</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER one ) (SIZE persona...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           train.SRC  \\\n",
       "0                 can i have a large bbq pulled pork   \n",
       "1  large pie with green pepper and with extra pep...   \n",
       "2                  i'd like a large vegetarian pizza   \n",
       "3  party size stuffed crust pie with american che...   \n",
       "4            can i have one personal sized artichoke   \n",
       "\n",
       "                                           train.EXR  \\\n",
       "0  (ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...   \n",
       "1  (ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...   \n",
       "2  (ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...   \n",
       "3  (ORDER (PIZZAORDER (NUMBER 1 ) (SIZE PARTY_SIZ...   \n",
       "4  (ORDER (PIZZAORDER (NUMBER 1 ) (SIZE PERSONAL_...   \n",
       "\n",
       "                                           train.TOP  \\\n",
       "0  (ORDER can i have (PIZZAORDER (NUMBER a ) (SIZ...   \n",
       "1  (ORDER (PIZZAORDER (SIZE large ) pie with (TOP...   \n",
       "2  (ORDER i'd like (PIZZAORDER (NUMBER a ) (SIZE ...   \n",
       "3  (ORDER (PIZZAORDER (SIZE party size ) (STYLE s...   \n",
       "4  (ORDER can i have (PIZZAORDER (NUMBER one ) (S...   \n",
       "\n",
       "                                 train.TOP-DECOUPLED  \n",
       "0  (ORDER (PIZZAORDER (NUMBER a ) (SIZE large ) (...  \n",
       "1  (ORDER (PIZZAORDER (SIZE large ) (TOPPING gree...  \n",
       "2  (ORDER (PIZZAORDER (NUMBER a ) (SIZE large ) (...  \n",
       "3  (ORDER (PIZZAORDER (SIZE party size ) (STYLE s...  \n",
       "4  (ORDER (PIZZAORDER (NUMBER one ) (SIZE persona...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dev.SRC</th>\n",
       "      <th>dev.EXR</th>\n",
       "      <th>dev.TOP</th>\n",
       "      <th>dev.PCFG_ERR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i want to order two medium pizzas with sausage...</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 2 ) (SIZE MEDIUM ) ...</td>\n",
       "      <td>(ORDER i want to order (PIZZAORDER (NUMBER two...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>five medium pizzas with tomatoes and ham</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 5 ) (SIZE MEDIUM ) ...</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER five ) (SIZE medium...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i need to order one large vegetarian pizza wit...</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...</td>\n",
       "      <td>(ORDER i need to order (PIZZAORDER (NUMBER one...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i'd like to order a large onion and pepper pizza</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...</td>\n",
       "      <td>(ORDER i'd like to order (PIZZAORDER (NUMBER a...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i'll have one pie along with pesto and ham but...</td>\n",
       "      <td>(ORDER (PIZZAORDER (NOT (TOPPING OLIVES ) ) (N...</td>\n",
       "      <td>(ORDER i'll have (PIZZAORDER (NUMBER one ) pie...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             dev.SRC  \\\n",
       "0  i want to order two medium pizzas with sausage...   \n",
       "1           five medium pizzas with tomatoes and ham   \n",
       "2  i need to order one large vegetarian pizza wit...   \n",
       "3   i'd like to order a large onion and pepper pizza   \n",
       "4  i'll have one pie along with pesto and ham but...   \n",
       "\n",
       "                                             dev.EXR  \\\n",
       "0  (ORDER (PIZZAORDER (NUMBER 2 ) (SIZE MEDIUM ) ...   \n",
       "1  (ORDER (PIZZAORDER (NUMBER 5 ) (SIZE MEDIUM ) ...   \n",
       "2  (ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...   \n",
       "3  (ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...   \n",
       "4  (ORDER (PIZZAORDER (NOT (TOPPING OLIVES ) ) (N...   \n",
       "\n",
       "                                             dev.TOP dev.PCFG_ERR  \n",
       "0  (ORDER i want to order (PIZZAORDER (NUMBER two...        False  \n",
       "1  (ORDER (PIZZAORDER (NUMBER five ) (SIZE medium...        False  \n",
       "2  (ORDER i need to order (PIZZAORDER (NUMBER one...        False  \n",
       "3  (ORDER i'd like to order (PIZZAORDER (NUMBER a...        False  \n",
       "4  (ORDER i'll have (PIZZAORDER (NUMBER one ) pie...        False  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train.SRC</th>\n",
       "      <th>train.EXR</th>\n",
       "      <th>train.TOP</th>\n",
       "      <th>train.TOP-DECOUPLED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>can i have a large bbq pulled pork</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...</td>\n",
       "      <td>(ORDER can i have (PIZZAORDER (NUMBER a ) (SIZ...</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER a ) (SIZE large ) (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>large pie with green pepper and with extra pep...</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...</td>\n",
       "      <td>(ORDER (PIZZAORDER (SIZE large ) pie with (TOP...</td>\n",
       "      <td>(ORDER (PIZZAORDER (SIZE large ) (TOPPING gree...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i'd like a large vegetarian pizza</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...</td>\n",
       "      <td>(ORDER i'd like (PIZZAORDER (NUMBER a ) (SIZE ...</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER a ) (SIZE large ) (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>party size stuffed crust pie with american che...</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 1 ) (SIZE PARTY_SIZ...</td>\n",
       "      <td>(ORDER (PIZZAORDER (SIZE party size ) (STYLE s...</td>\n",
       "      <td>(ORDER (PIZZAORDER (SIZE party size ) (STYLE s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>can i have one personal sized artichoke</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 1 ) (SIZE PERSONAL_...</td>\n",
       "      <td>(ORDER can i have (PIZZAORDER (NUMBER one ) (S...</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER one ) (SIZE persona...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           train.SRC  \\\n",
       "0                 can i have a large bbq pulled pork   \n",
       "1  large pie with green pepper and with extra pep...   \n",
       "2                  i'd like a large vegetarian pizza   \n",
       "3  party size stuffed crust pie with american che...   \n",
       "4            can i have one personal sized artichoke   \n",
       "\n",
       "                                           train.EXR  \\\n",
       "0  (ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...   \n",
       "1  (ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...   \n",
       "2  (ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...   \n",
       "3  (ORDER (PIZZAORDER (NUMBER 1 ) (SIZE PARTY_SIZ...   \n",
       "4  (ORDER (PIZZAORDER (NUMBER 1 ) (SIZE PERSONAL_...   \n",
       "\n",
       "                                           train.TOP  \\\n",
       "0  (ORDER can i have (PIZZAORDER (NUMBER a ) (SIZ...   \n",
       "1  (ORDER (PIZZAORDER (SIZE large ) pie with (TOP...   \n",
       "2  (ORDER i'd like (PIZZAORDER (NUMBER a ) (SIZE ...   \n",
       "3  (ORDER (PIZZAORDER (SIZE party size ) (STYLE s...   \n",
       "4  (ORDER can i have (PIZZAORDER (NUMBER one ) (S...   \n",
       "\n",
       "                                 train.TOP-DECOUPLED  \n",
       "0  (ORDER (PIZZAORDER (NUMBER a ) (SIZE large ) (...  \n",
       "1  (ORDER (PIZZAORDER (SIZE large ) (TOPPING gree...  \n",
       "2  (ORDER (PIZZAORDER (NUMBER a ) (SIZE large ) (...  \n",
       "3  (ORDER (PIZZAORDER (SIZE party size ) (STYLE s...  \n",
       "4  (ORDER (PIZZAORDER (NUMBER one ) (SIZE persona...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"train.SRC\"] = df_train[\"train.SRC\"].apply(clean_text)\n",
    "df_dev[\"dev.SRC\"] = df_dev[\"dev.SRC\"].apply(clean_text)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatizer = WordNetLemmatizer()\n",
    "# df_train['train.SRC'] = df_train['train.SRC'].apply(lemmatizer.lemmatize)\n",
    "# df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train.SRC</th>\n",
       "      <th>train.EXR</th>\n",
       "      <th>train.TOP</th>\n",
       "      <th>train.TOP-DECOUPLED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>can i have a large bbq pulled pork</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...</td>\n",
       "      <td>(ORDER can i have (PIZZAORDER (NUMBER a ) (SIZ...</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER a ) (SIZE large ) (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>large pie with green pepper and with extra pep...</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...</td>\n",
       "      <td>(ORDER (PIZZAORDER (SIZE large ) pie with (TOP...</td>\n",
       "      <td>(ORDER (PIZZAORDER (SIZE large ) (TOPPING gree...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i would like a large vegetarian pizza</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...</td>\n",
       "      <td>(ORDER i'd like (PIZZAORDER (NUMBER a ) (SIZE ...</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER a ) (SIZE large ) (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>party size stuffed crust pie with american che...</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 1 ) (SIZE PARTY_SIZ...</td>\n",
       "      <td>(ORDER (PIZZAORDER (SIZE party size ) (STYLE s...</td>\n",
       "      <td>(ORDER (PIZZAORDER (SIZE party size ) (STYLE s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>can i have one personal sized artichoke</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 1 ) (SIZE PERSONAL_...</td>\n",
       "      <td>(ORDER can i have (PIZZAORDER (NUMBER one ) (S...</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER one ) (SIZE persona...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           train.SRC  \\\n",
       "0                 can i have a large bbq pulled pork   \n",
       "1  large pie with green pepper and with extra pep...   \n",
       "2              i would like a large vegetarian pizza   \n",
       "3  party size stuffed crust pie with american che...   \n",
       "4            can i have one personal sized artichoke   \n",
       "\n",
       "                                           train.EXR  \\\n",
       "0  (ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...   \n",
       "1  (ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...   \n",
       "2  (ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...   \n",
       "3  (ORDER (PIZZAORDER (NUMBER 1 ) (SIZE PARTY_SIZ...   \n",
       "4  (ORDER (PIZZAORDER (NUMBER 1 ) (SIZE PERSONAL_...   \n",
       "\n",
       "                                           train.TOP  \\\n",
       "0  (ORDER can i have (PIZZAORDER (NUMBER a ) (SIZ...   \n",
       "1  (ORDER (PIZZAORDER (SIZE large ) pie with (TOP...   \n",
       "2  (ORDER i'd like (PIZZAORDER (NUMBER a ) (SIZE ...   \n",
       "3  (ORDER (PIZZAORDER (SIZE party size ) (STYLE s...   \n",
       "4  (ORDER can i have (PIZZAORDER (NUMBER one ) (S...   \n",
       "\n",
       "                                 train.TOP-DECOUPLED  \n",
       "0  (ORDER (PIZZAORDER (NUMBER a ) (SIZE large ) (...  \n",
       "1  (ORDER (PIZZAORDER (SIZE large ) (TOPPING gree...  \n",
       "2  (ORDER (PIZZAORDER (NUMBER a ) (SIZE large ) (...  \n",
       "3  (ORDER (PIZZAORDER (SIZE party size ) (STYLE s...  \n",
       "4  (ORDER (PIZZAORDER (NUMBER one ) (SIZE persona...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"train.SRC\"] = df_train[\"train.SRC\"].apply(expnad_abb2)\n",
    "df_dev[\"dev.SRC\"] = df_dev[\"dev.SRC\"].apply(expnad_abb2)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train.SRC</th>\n",
       "      <th>train.EXR</th>\n",
       "      <th>train.TOP</th>\n",
       "      <th>train.TOP-DECOUPLED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>large bbq pulled pork</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...</td>\n",
       "      <td>(ORDER can i have (PIZZAORDER (NUMBER a ) (SIZ...</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER a ) (SIZE large ) (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>large pie green pepper and extra peperonni</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...</td>\n",
       "      <td>(ORDER (PIZZAORDER (SIZE large ) pie with (TOP...</td>\n",
       "      <td>(ORDER (PIZZAORDER (SIZE large ) (TOPPING gree...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>large vegetarian pizza</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...</td>\n",
       "      <td>(ORDER i'd like (PIZZAORDER (NUMBER a ) (SIZE ...</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER a ) (SIZE large ) (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>party size stuffed crust pie american cheese a...</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 1 ) (SIZE PARTY_SIZ...</td>\n",
       "      <td>(ORDER (PIZZAORDER (SIZE party size ) (STYLE s...</td>\n",
       "      <td>(ORDER (PIZZAORDER (SIZE party size ) (STYLE s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>one personal sized artichoke</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 1 ) (SIZE PERSONAL_...</td>\n",
       "      <td>(ORDER can i have (PIZZAORDER (NUMBER one ) (S...</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER one ) (SIZE persona...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           train.SRC  \\\n",
       "0                              large bbq pulled pork   \n",
       "1         large pie green pepper and extra peperonni   \n",
       "2                             large vegetarian pizza   \n",
       "3  party size stuffed crust pie american cheese a...   \n",
       "4                       one personal sized artichoke   \n",
       "\n",
       "                                           train.EXR  \\\n",
       "0  (ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...   \n",
       "1  (ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...   \n",
       "2  (ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...   \n",
       "3  (ORDER (PIZZAORDER (NUMBER 1 ) (SIZE PARTY_SIZ...   \n",
       "4  (ORDER (PIZZAORDER (NUMBER 1 ) (SIZE PERSONAL_...   \n",
       "\n",
       "                                           train.TOP  \\\n",
       "0  (ORDER can i have (PIZZAORDER (NUMBER a ) (SIZ...   \n",
       "1  (ORDER (PIZZAORDER (SIZE large ) pie with (TOP...   \n",
       "2  (ORDER i'd like (PIZZAORDER (NUMBER a ) (SIZE ...   \n",
       "3  (ORDER (PIZZAORDER (SIZE party size ) (STYLE s...   \n",
       "4  (ORDER can i have (PIZZAORDER (NUMBER one ) (S...   \n",
       "\n",
       "                                 train.TOP-DECOUPLED  \n",
       "0  (ORDER (PIZZAORDER (NUMBER a ) (SIZE large ) (...  \n",
       "1  (ORDER (PIZZAORDER (SIZE large ) (TOPPING gree...  \n",
       "2  (ORDER (PIZZAORDER (NUMBER a ) (SIZE large ) (...  \n",
       "3  (ORDER (PIZZAORDER (SIZE party size ) (STYLE s...  \n",
       "4  (ORDER (PIZZAORDER (NUMBER one ) (SIZE persona...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"train.SRC\"] = df_train[\"train.SRC\"].apply(remove_stopwords)\n",
    "df_dev[\"dev.SRC\"] = df_dev[\"dev.SRC\"].apply(remove_stopwords)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train.SRC</th>\n",
       "      <th>train.EXR</th>\n",
       "      <th>train.TOP</th>\n",
       "      <th>train.TOP-DECOUPLED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>large bbq pulled pork</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...</td>\n",
       "      <td>(ORDER can i have (PIZZAORDER (NUMBER a ) (SIZ...</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER a ) (SIZE large ) (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>large pie green pepper extra peperonni</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...</td>\n",
       "      <td>(ORDER (PIZZAORDER (SIZE large ) pie with (TOP...</td>\n",
       "      <td>(ORDER (PIZZAORDER (SIZE large ) (TOPPING gree...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>large vegetarian pizza</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...</td>\n",
       "      <td>(ORDER i'd like (PIZZAORDER (NUMBER a ) (SIZE ...</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER a ) (SIZE large ) (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>party size stuffed crust pie american cheese m...</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 1 ) (SIZE PARTY_SIZ...</td>\n",
       "      <td>(ORDER (PIZZAORDER (SIZE party size ) (STYLE s...</td>\n",
       "      <td>(ORDER (PIZZAORDER (SIZE party size ) (STYLE s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>one personal sized artichoke</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 1 ) (SIZE PERSONAL_...</td>\n",
       "      <td>(ORDER can i have (PIZZAORDER (NUMBER one ) (S...</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER one ) (SIZE persona...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           train.SRC  \\\n",
       "0                              large bbq pulled pork   \n",
       "1             large pie green pepper extra peperonni   \n",
       "2                             large vegetarian pizza   \n",
       "3  party size stuffed crust pie american cheese m...   \n",
       "4                       one personal sized artichoke   \n",
       "\n",
       "                                           train.EXR  \\\n",
       "0  (ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...   \n",
       "1  (ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...   \n",
       "2  (ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...   \n",
       "3  (ORDER (PIZZAORDER (NUMBER 1 ) (SIZE PARTY_SIZ...   \n",
       "4  (ORDER (PIZZAORDER (NUMBER 1 ) (SIZE PERSONAL_...   \n",
       "\n",
       "                                           train.TOP  \\\n",
       "0  (ORDER can i have (PIZZAORDER (NUMBER a ) (SIZ...   \n",
       "1  (ORDER (PIZZAORDER (SIZE large ) pie with (TOP...   \n",
       "2  (ORDER i'd like (PIZZAORDER (NUMBER a ) (SIZE ...   \n",
       "3  (ORDER (PIZZAORDER (SIZE party size ) (STYLE s...   \n",
       "4  (ORDER can i have (PIZZAORDER (NUMBER one ) (S...   \n",
       "\n",
       "                                 train.TOP-DECOUPLED  \n",
       "0  (ORDER (PIZZAORDER (NUMBER a ) (SIZE large ) (...  \n",
       "1  (ORDER (PIZZAORDER (SIZE large ) (TOPPING gree...  \n",
       "2  (ORDER (PIZZAORDER (NUMBER a ) (SIZE large ) (...  \n",
       "3  (ORDER (PIZZAORDER (SIZE party size ) (STYLE s...  \n",
       "4  (ORDER (PIZZAORDER (NUMBER one ) (SIZE persona...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"train.SRC\"] = df_train[\"train.SRC\"].apply(handle_negation)\n",
    "df_dev[\"dev.SRC\"] = df_dev[\"dev.SRC\"].apply(handle_negation)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train.SRC</th>\n",
       "      <th>train.EXR</th>\n",
       "      <th>train.TOP</th>\n",
       "      <th>train.TOP-DECOUPLED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>larg  bbq  pull  pork</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...</td>\n",
       "      <td>(ORDER can i have (PIZZAORDER (NUMBER a ) (SIZ...</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER a ) (SIZE large ) (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>larg  pie  green  pepper  extra  peperonni</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...</td>\n",
       "      <td>(ORDER (PIZZAORDER (SIZE large ) pie with (TOP...</td>\n",
       "      <td>(ORDER (PIZZAORDER (SIZE large ) (TOPPING gree...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>larg  vegetarian  pizza</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...</td>\n",
       "      <td>(ORDER i'd like (PIZZAORDER (NUMBER a ) (SIZE ...</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER a ) (SIZE large ) (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>parti  size  stuf  crust  pie  american  chees...</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 1 ) (SIZE PARTY_SIZ...</td>\n",
       "      <td>(ORDER (PIZZAORDER (SIZE party size ) (STYLE s...</td>\n",
       "      <td>(ORDER (PIZZAORDER (SIZE party size ) (STYLE s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>one  person  size  artichok</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 1 ) (SIZE PERSONAL_...</td>\n",
       "      <td>(ORDER can i have (PIZZAORDER (NUMBER one ) (S...</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER one ) (SIZE persona...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           train.SRC  \\\n",
       "0                            larg  bbq  pull  pork     \n",
       "1       larg  pie  green  pepper  extra  peperonni     \n",
       "2                          larg  vegetarian  pizza     \n",
       "3  parti  size  stuf  crust  pie  american  chees...   \n",
       "4                      one  person  size  artichok     \n",
       "\n",
       "                                           train.EXR  \\\n",
       "0  (ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...   \n",
       "1  (ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...   \n",
       "2  (ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...   \n",
       "3  (ORDER (PIZZAORDER (NUMBER 1 ) (SIZE PARTY_SIZ...   \n",
       "4  (ORDER (PIZZAORDER (NUMBER 1 ) (SIZE PERSONAL_...   \n",
       "\n",
       "                                           train.TOP  \\\n",
       "0  (ORDER can i have (PIZZAORDER (NUMBER a ) (SIZ...   \n",
       "1  (ORDER (PIZZAORDER (SIZE large ) pie with (TOP...   \n",
       "2  (ORDER i'd like (PIZZAORDER (NUMBER a ) (SIZE ...   \n",
       "3  (ORDER (PIZZAORDER (SIZE party size ) (STYLE s...   \n",
       "4  (ORDER can i have (PIZZAORDER (NUMBER one ) (S...   \n",
       "\n",
       "                                 train.TOP-DECOUPLED  \n",
       "0  (ORDER (PIZZAORDER (NUMBER a ) (SIZE large ) (...  \n",
       "1  (ORDER (PIZZAORDER (SIZE large ) (TOPPING gree...  \n",
       "2  (ORDER (PIZZAORDER (NUMBER a ) (SIZE large ) (...  \n",
       "3  (ORDER (PIZZAORDER (SIZE party size ) (STYLE s...  \n",
       "4  (ORDER (PIZZAORDER (NUMBER one ) (SIZE persona...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"train.SRC\"] = df_train[\"train.SRC\"].apply(tokenize_and_lemmatize)\n",
    "df_dev[\"dev.SRC\"] = df_dev[\"dev.SRC\"].apply(tokenize_and_lemmatize)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_data = df_train[\"train.SRC\"]\n",
    "\n",
    "tf_idf_data = vectorizer.fit_transform(tf_idf_data)\n",
    "# tf_idf_data = tf_idf_data.apply(vectorizer.fit_transform)\n",
    "# X_train_tfidf = vectorizer.fit_transform(temp_data)\n",
    "# X_test_tfidf = vectorizer.transform(temp_data)\n",
    "# print(X_train_tfidf)\n",
    "# print(tf_idf_data)\n",
    "# df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['10' '11' '12' '13' '14' '15' '16' '20' '200' '500' 'ale' 'alfredo'\n",
      " 'also' 'american' 'anchovi' 'appl' 'applewood' 'artichok' 'arugula'\n",
      " 'bacon' 'balsam' 'balzam' 'banana' 'barbecu' 'basil' 'bay' 'bbq' 'bean'\n",
      " 'beef' 'big' 'bit' 'black' 'bottl' 'broccoli' 'brocoli' 'buffalo' 'can'\n",
      " 'caramel' 'carrot' 'cauliflow' 'cheddar' 'chees' 'cheeseburg' 'cherri'\n",
      " 'chicago' 'chicken' 'chorizo' 'chorrizo' 'coffe' 'coke' 'combin' 'crust'\n",
      " 'cumin' 'deep' 'deepdish' 'dew' 'diet' 'dish' 'doctor' 'dough' 'dr' 'dri'\n",
      " 'eight' 'eleven' 'everi' 'everyth' 'extra' 'fanta' 'fat' 'feta' 'fifteen'\n",
      " 'five' 'fl' 'flake' 'fluid' 'four' 'fourteen' 'free' 'fri' 'garlic'\n",
      " 'ginger' 'glaze' 'gluten' 'green' 'grill' 'ground' 'ham' 'hawaiian'\n",
      " 'high' 'hot' 'ice' 'italian' 'jalapeno' 'kalamata' 'keto' 'larg' 'leav'\n",
      " 'lemon' 'lettuc' 'liter' 'littl' 'lot' 'lover' 'low' 'lunch' 'margarita'\n",
      " 'margherita' 'meat' 'meatbal' 'meatlov' 'med' 'mediterranean' 'medium'\n",
      " 'mexican' 'millilit' 'ml' 'mountain' 'mozarella' 'mozzarella' 'mushroom'\n",
      " 'napolitan' 'napolitana' 'neapolitan' 'need' 'new' 'nine' 'not_alfredo'\n",
      " 'not_american' 'not_anchovi' 'not_appl' 'not_applewood' 'not_artichok'\n",
      " 'not_arugula' 'not_bacon' 'not_balsam' 'not_balzam' 'not_banana'\n",
      " 'not_barbecu' 'not_basil' 'not_bay' 'not_bbq' 'not_bean' 'not_beef'\n",
      " 'not_black' 'not_broccoli' 'not_brocoli' 'not_buffalo' 'not_caramel'\n",
      " 'not_carrot' 'not_cheddar' 'not_chees' 'not_cheeseburg' 'not_cherri'\n",
      " 'not_chicken' 'not_chorizo' 'not_chorrizo' 'not_crust' 'not_cumin'\n",
      " 'not_dri' 'not_fat' 'not_feta' 'not_flake' 'not_fri' 'not_garlic'\n",
      " 'not_glaze' 'not_green' 'not_grill' 'not_ground' 'not_ham' 'not_hot'\n",
      " 'not_italian' 'not_jalapeno' 'not_kalamata' 'not_leav' 'not_lettuc'\n",
      " 'not_low' 'not_mani' 'not_meatbal' 'not_mozarella' 'not_mozzarella'\n",
      " 'not_much' 'not_mushroom' 'not_oil' 'not_oliv' 'not_onion' 'not_oregano'\n",
      " 'not_parmesan' 'not_parsley' 'not_pea' 'not_pecorino' 'not_peperoni'\n",
      " 'not_peperonni' 'not_peperroni' 'not_peperronni' 'not_pepper'\n",
      " 'not_pepperoni' 'not_peppperoni' 'not_pesto' 'not_pickl' 'not_pineapl'\n",
      " 'not_pineappl' 'not_pork' 'not_powder' 'not_pull' 'not_ranch' 'not_red'\n",
      " 'not_ricotta' 'not_roast' 'not_rosemari' 'not_salami' 'not_sauc'\n",
      " 'not_sausag' 'not_shrimp' 'not_spice' 'not_spici' 'not_spinach'\n",
      " 'not_thin' 'not_tomato' 'not_tuna' 'not_vegan' 'not_white' 'not_wood'\n",
      " 'not_yellow' 'oil' 'oliv' 'one' 'onion' 'oregano' 'ounc' 'oz' 'pan'\n",
      " 'parmesan' 'parsley' 'parti' 'pea' 'pecorino' 'pellegrino' 'peper'\n",
      " 'peperoni' 'peperonni' 'peperroni' 'peperronni' 'pepper' 'pepperoni'\n",
      " 'peppperoni' 'pepsi' 'perrier' 'person' 'pesto' 'pickl' 'pie' 'pineapl'\n",
      " 'pineappl' 'pizza' 'pork' 'powder' 'pull' 'ranch' 'red' 'regular'\n",
      " 'ricotta' 'rise' 'roast' 'rosemari' 'salami' 'san' 'sauc' 'sausag'\n",
      " 'seven' 'shrimp' 'six' 'sixteen' 'size' 'small' 'soda' 'sourdough'\n",
      " 'spice' 'spici' 'spinach' 'sprite' 'stuf' 'style' 'suprem' 'tea' 'ten'\n",
      " 'thick' 'thin' 'thirteen' 'three' 'tini' 'tomato' 'top' 'tuna' 'twelv'\n",
      " 'two' 'up' 'vegan' 'veget' 'vegetarian' 'veggi' 'water' 'white' 'wood'\n",
      " 'work' 'yellow' 'york' 'yorker' 'zero']\n",
      "Document-Term Matrix:\n",
      " [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initialize the CountVectorizer\n",
    "count_vectroizer = CountVectorizer()\n",
    "\n",
    "bow = df_train[\"train.SRC\"]\n",
    "\n",
    "# Fit and transform the corpus to a document-term matrix\n",
    "X = count_vectroizer.fit_transform(bow)\n",
    "\n",
    "vocab = count_vectroizer.get_feature_names_out()\n",
    "\n",
    "X_dense = X.toarray()\n",
    "# Print the vocabulary and document-term matrix\n",
    "print(\"Vocabulary:\", vocab)\n",
    "print(\"Document-Term Matrix:\\n\", X_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneHotEncoder(sparse_output=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Initialize OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "temp_data = df_train[\"train.SRC\"].head(20)\n",
    "# Fit and transform the categorical columns\n",
    "one_hot_encoded = encoder.fit([temp_data])\n",
    "print(one_hot_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "\n",
    "pre_trained = KeyedVectors.load_word2vec_format(\n",
    "    \"GoogleNews-vectors-negative300.bin\", binary=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 31 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m pre_trained_model\u001b[38;5;241m.\u001b[39mwv\u001b[38;5;241m.\u001b[39mvectors \u001b[38;5;241m=\u001b[39m pre_trained_model\u001b[38;5;241m.\u001b[39mwv\u001b[38;5;241m.\u001b[39mvectors[:\u001b[38;5;28mlen\u001b[39m(pre_trained_model\u001b[38;5;241m.\u001b[39mwv\u001b[38;5;241m.\u001b[39mindex_to_key)]\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Step 4: Intersect with pre-trained embeddings\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[43mpre_trained_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintersect_word2vec_format\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGoogleNews-vectors-negative300.bin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbinary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Train further on your dataset\u001b[39;00m\n\u001b[0;32m     21\u001b[0m pre_trained_model\u001b[38;5;241m.\u001b[39mtrain(custom_sentences, total_examples\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(custom_sentences), epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Ahmed Samy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gensim\\models\\keyedvectors.py:1771\u001b[0m, in \u001b[0;36mKeyedVectors.intersect_word2vec_format\u001b[1;34m(self, fname, lockf, binary, encoding, unicode_errors)\u001b[0m\n\u001b[0;32m   1769\u001b[0m             overlap_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1770\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvectors[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_index(word)] \u001b[38;5;241m=\u001b[39m weights\n\u001b[1;32m-> 1771\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvectors_lockf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m lockf  \u001b[38;5;66;03m# lock-factor: 0.0=no changes\u001b[39;00m\n\u001b[0;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line_no, line \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(fin):\n",
      "\u001b[1;31mIndexError\u001b[0m: index 31 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "# # Load pre-trained Word2Vec\n",
    "# test_sentences = df_train[\"train.SRC\"].head(10000)\n",
    "\n",
    "# # Convert to Word2Vec model for fine-tuning\n",
    "# pre_trained_model = Word2Vec(min_count=1,workers=14,vector_size=300)\n",
    "\n",
    "# pre_trained_model.build_vocab(test_sentences)\n",
    "\n",
    "# # Build vocabulary from the pre-trained model's keys\n",
    "# pre_trained_model.build_vocab([list(pre_trained.key_to_index.keys())], update=True)\n",
    "\n",
    "# Initialize weights with the pre-trained vectors\n",
    "pre_trained_model.wv.vectors = pre_trained_model.wv.vectors[\n",
    "    : len(pre_trained_model.wv.index_to_key)\n",
    "]\n",
    "\n",
    "# Step 4: Intersect with pre-trained embeddings\n",
    "pre_trained_model.wv.intersect_word2vec_format(\n",
    "    \"GoogleNews-vectors-negative300.bin\", binary=True, lockf=1.0\n",
    ")\n",
    "\n",
    "\n",
    "# Train further on your dataset\n",
    "pre_trained_model.train(test_sentences, total_examples=len(custom_sentences), epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Index: {'<OOV>': 1, 'e': 2, 'p': 3, 'a': 4, 'i': 5, 'r': 6, 'n': 7, 'o': 8, 't': 9, 's': 10, 'z': 11, 'c': 12, 'l': 13, 'h': 14, 'm': 15, 'u': 16, 'g': 17, 'b': 18, 'd': 19, 'x': 20, 'v': 21, 'f': 22, 'k': 23, 'w': 24, 'y': 25, 'q': 26, 'j': 27}\n",
      "Padded Sequences: [[18 26  3 ...  8  6 23]\n",
      " [ 4  3  2 ...  7  7  5]\n",
      " [ 4  6  5 ... 11 11  4]\n",
      " ...\n",
      " [ 9  3  2 ...  7  7  5]\n",
      " [ 2 13  6 ...  5  8  7]\n",
      " [15  8 11 ... 13 13  4]]\n"
     ]
    }
   ],
   "source": [
    "custom_sentences = df_train[\"train.SRC\"].head(10000)\n",
    "\n",
    "tokenizer = Tokenizer(num_words=500, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(\n",
    "    [\" \".join(tokens) for tokens in custom_sentences]\n",
    ")  # Flatten sentences for Keras\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "sequences_train = tokenizer.texts_to_sequences(\n",
    "    [\" \".join(tokens) for tokens in custom_sentences]\n",
    ")  # transforms each text in texts to a sequence of integers\n",
    "padded_sequences_train = pad_sequences(sequences_train, maxlen=10, padding=\"post\")\n",
    "\n",
    "print(\"Word Index:\", word_index)\n",
    "print(\"Padded Sequences:\", padded_sequences_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(\n",
    "    sentences=custom_sentences, min_count=1, workers=14, vector_size=300\n",
    ")\n",
    "\n",
    "embedding_dim = w2v_model.vector_size  # Size of Word2Vec embeddings\n",
    "vocab_size = len(word_index) + 1  # Add 1 for padding token\n",
    "\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    if word in w2v_model.wv:\n",
    "        embedding_matrix[i] = w2v_model.wv[word]  # Assign pre-trained vector\n",
    "    else:\n",
    "        embedding_matrix[i] = np.random.normal(\n",
    "            size=(embedding_dim,)\n",
    "        )  # Random vector for unknown words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_10\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_10\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ ?                      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,700</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_10 (\u001b[38;5;33mEmbedding\u001b[0m)        │ ?                      │         \u001b[38;5;34m8,700\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_10 (\u001b[38;5;33mLSTM\u001b[0m)                  │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,700</span> (33.98 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,700\u001b[0m (33.98 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,700</span> (33.98 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m8,700\u001b[0m (33.98 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Index: {'<OOV>': 1, 'e': 2, 'p': 3, 'r': 4, 'i': 5, 'o': 6, 'n': 7, 't': 8, 'a': 9, 'z': 10, 's': 11, 'g': 12, 'd': 13, 'm': 14, 'c': 15, 'l': 16, 'u': 17, 'b': 18, 'y': 19, '1': 20, 'h': 21, 'x': 22, 'q': 23, 'f': 24, 'k': 25, 'v': 26, 'w': 27, 'j': 28}\n",
      "Padded Sequences: [[ 3 17 16 ...  6  4 25]\n",
      " [12  3  2 ...  6  7  5]\n",
      " [26  2 12 ...  5  9  7]\n",
      " ...\n",
      " [12  3  2 ...  6  7  5]\n",
      " [ 5 10  2 ...  6  7 11]\n",
      " [ 2 16 16 ...  2 11  2]]\n"
     ]
    }
   ],
   "source": [
    "test_sentences = df_train[\"train.EXR\"].head(10000)\n",
    "\n",
    "tokenizer = Tokenizer(num_words=500, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(\n",
    "    [\" \".join(tokens) for tokens in test_sentences]\n",
    ")  # Flatten sentences for Keras\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(\n",
    "    [\" \".join(tokens) for tokens in test_sentences]\n",
    ")  # transforms each text in texts to a sequence of integers\n",
    "padded_sequences = pad_sequences(sequences, maxlen=10, padding=\"post\")\n",
    "\n",
    "print(\"Word Index:\", word_index)\n",
    "print(\"Padded Sequences:\", padded_sequences)\n",
    "embedding_dim = w2v_model.vector_size  # Size of Word2Vec embeddings\n",
    "vocab_size = len(word_index) + 1  # Add 1 for padding token\n",
    "\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    if word in w2v_model.wv:\n",
    "        embedding_matrix[i] = w2v_model.wv[word]  # Assign pre-trained vector\n",
    "    else:\n",
    "        embedding_matrix[i] = np.random.normal(\n",
    "            size=(embedding_dim,)\n",
    "        )  # Random vector for unknown words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "model = Sequential(\n",
    "    [\n",
    "        Embedding(\n",
    "            input_dim=vocab_size,\n",
    "            output_dim=embedding_dim,\n",
    "            weights=[embedding_matrix],\n",
    "            input_length=padded_sequences_train.shape[1],\n",
    "            trainable=False,\n",
    "        ),\n",
    "        LSTM(128, return_sequences=False),\n",
    "        Dense(padded_sequences_train.shape[1], activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 3s - 10ms/step - accuracy: 0.2338 - loss: 236.8394\n",
      "Epoch 2/10\n",
      "313/313 - 2s - 5ms/step - accuracy: 0.2360 - loss: 244.8951\n",
      "Epoch 3/10\n",
      "313/313 - 2s - 5ms/step - accuracy: 0.2360 - loss: 247.0565\n",
      "Epoch 4/10\n",
      "313/313 - 2s - 5ms/step - accuracy: 0.2360 - loss: 248.9971\n",
      "Epoch 5/10\n",
      "313/313 - 2s - 5ms/step - accuracy: 0.2360 - loss: 250.9110\n",
      "Epoch 6/10\n",
      "313/313 - 2s - 5ms/step - accuracy: 0.2360 - loss: 252.8540\n",
      "Epoch 7/10\n",
      "313/313 - 2s - 5ms/step - accuracy: 0.2360 - loss: 254.8490\n",
      "Epoch 8/10\n",
      "313/313 - 2s - 5ms/step - accuracy: 0.2360 - loss: 256.9070\n",
      "Epoch 9/10\n",
      "313/313 - 2s - 5ms/step - accuracy: 0.2360 - loss: 259.0325\n",
      "Epoch 10/10\n",
      "313/313 - 2s - 6ms/step - accuracy: 0.2360 - loss: 261.2292\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    padded_sequences_train,  # Input sequences (numerical)\n",
    "    padded_sequences,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    # validation_data=(test_padded, test_labels),  # Validation data\n",
    "    verbose=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN, Dense\n",
    "\n",
    "# Define the model architecture\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(units=32, input_shape=(None, 1)))\n",
    "model.add(Dense(units=1, activation=\"sigmoid\"))\n",
    "# Compile the model\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=32)\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "# Make predictions using the model\n",
    "predictions = model.predict(x_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, activation=\"relu\", input_shape=(n_input, n_features)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "model.summary()\n",
    "model.fit(generator, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=500, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(\n",
    "    # df_train[\"train.SRC\"]\n",
    "    df_train[\"train.SRC\"].head(10)\n",
    ")  # updates internal vocabulary based on a list of texts\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(\n",
    "    df_train[\"train.SRC\"]\n",
    ")  # transforms each text in texts to a sequence of integers\n",
    "padded_sequences = pad_sequences(sequences, maxlen=100, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"padded_seq\"] = list(padded_sequences)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
