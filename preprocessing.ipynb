{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, SimpleRNN, GRU, Dropout,Input\n",
    "from nltk.stem import PorterStemmer, SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import TreebankWordTokenizer, word_tokenize, MWETokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models import Word2Vec \n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"dataset/\"\n",
    "CONTRACTIONS = {\n",
    "    \"n't\": \"not\",\n",
    "    \"'s\": \"is\",\n",
    "    \"'re\": \"are\",\n",
    "    \"'m\": \"am\",\n",
    "    \"'ll\": \"will\",\n",
    "    \"'ve\": \"have\",\n",
    "    \"'d\": \"would\",\n",
    "    \"'em\": \"them\",\n",
    "    \"'all\": \"all\",\n",
    "    \"'cause\": \"because\",\n",
    "    \"'clock\": \"oclock\",\n",
    "    \"'tis\": \"it is\",\n",
    "    \"'twas\": \"it was\",\n",
    "    \"'tween\": \"between\",\n",
    "    \"'twere\": \"it were\",\n",
    "    \"'twould\": \"it would\",\n",
    "    \"'twixt\": \"betwixt\",\n",
    "    \"'twill\": \"it will\",\n",
    "    \"'til\": \"until\",\n",
    "    \"'bout\": \"about\",\n",
    "    \"'cept\": \"except\",\n",
    "    \"'cos\": \"because\",\n",
    "    \"'fore\": \"before\",\n",
    "    \"'round\": \"around\",\n",
    "    \"'n'\": \"and\",\n",
    "    \"'neath\": \"beneath\",\n",
    "    \"'nother\": \"another\",\n",
    "    \"'nuff\": \"enough\",\n",
    "}\n",
    "negation_words = {\n",
    "    \"no\",\n",
    "    \"not\",\n",
    "    \"none\",\n",
    "    \"never\",\n",
    "    \"without\",\n",
    "    \"avoid\",\n",
    "    \"neither\",\n",
    "    \"nor\",\n",
    "    \"hate\",\n",
    "    \"hold\",\n",
    "}\n",
    "tokenizer = TreebankWordTokenizer()  # Treebank Word Tokenizer\n",
    "lemmatizer = WordNetLemmatizer()  # WordNet Lemmatizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "# tokenizer = MWETokenizer() # Multi-Word Expression Tokenizer\n",
    "stemmer = (\n",
    "    PorterStemmer()\n",
    ")  # Porter Stemmer  # changes ordering to order and cheese to chees it may help us\n",
    "# stemmer = SnowballStemmer(\"english\") # ! The same as porter stemmer\n",
    "stop_negation_words = {\"and\", \"but\"}\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "stop_words = stop_words - negation_words - stop_negation_words\n",
    "stop_words.update({\"would\", \"like\", \"get\", \"want\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Clean text from any unneeded characters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r\"[^\\w']\", \" \", text)  # Remove non-word characters\n",
    "    text = re.sub(r\"\\s+\", \" \", text)  # Remove multiple spaces\n",
    "    text = text.lower().strip()  # Lowercase and strip whitespace\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expnad_abb(text):\n",
    "    text = text.replace(\"can't\", \"can not\")\n",
    "    text = text.replace(\"won't\", \"will not\")\n",
    "    text = text.replace(\"n't\", \" not\")\n",
    "    text = text.replace(\"'ll\", \" will\")\n",
    "    text = text.replace(\"'ve\", \" have\")\n",
    "    text = text.replace(\"'re\", \" are\")\n",
    "    text = text.replace(\"'m\", \" am\")\n",
    "    text = text.replace(\"'d\", \" would\")\n",
    "    return text\n",
    "\n",
    "\n",
    "def expnad_abb2(text):\n",
    "\n",
    "    pattern = re.compile(\n",
    "        r\"(\" + \"|\".join(re.escape(key) for key in CONTRACTIONS.keys()) + r\")\"\n",
    "    )\n",
    "    expanded_text = pattern.sub(lambda x: \" \" + CONTRACTIONS[x.group()], text)\n",
    "    return expanded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return \" \".join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_negation(text):\n",
    "    # Look for patterns like \"no [word1] [word2] ...\" and transform them\n",
    "    words = text.split()\n",
    "    transformed_words = []\n",
    "    negation_flag = False  # To track if we're negating\n",
    "\n",
    "    for i, word in enumerate(words):\n",
    "        if word.lower() in negation_words:  # Trigger negation\n",
    "            negation_flag = True\n",
    "            continue  # Skip adding \"no\" to the transformed text\n",
    "        elif negation_flag and (\n",
    "            not re.match(r\"[a-zA-Z]+\", word) or word.lower() in stop_negation_words\n",
    "        ):  # End negation on punctuation or 'and'\n",
    "            negation_flag = False\n",
    "\n",
    "        # Prefix \"NOT_\" if negation flag is set\n",
    "        if negation_flag:\n",
    "            transformed_words.append(f\"NOT_{word}\")\n",
    "            if word in [\"much\"]:\n",
    "                negation_flag = False\n",
    "        else:\n",
    "            if word.lower() not in stop_negation_words:\n",
    "                transformed_words.append(word)\n",
    "\n",
    "    return \" \".join(transformed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_lemmatize(text: str):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    final_string = \"\"\n",
    "    # stemmed_tokens = []\n",
    "    for token in tokens:\n",
    "        stemmed_token = stemmer.stem(token, False) + \" \"\n",
    "        # I think this is better than lemmatization\n",
    "        final_string += stemmed_token + \" \"\n",
    "        # stemmed_tokens.append(stemmed_token)\n",
    "        # final_string += lemmatizer.lemmatize(token) + \" \"  # Didn't do anything\n",
    "    return final_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT_ordering NOT_pizza NOT_extra NOT_cheese NOT_soda NOT_organization\n"
     ]
    }
   ],
   "source": [
    "cleaned_text = handle_negation(\n",
    "    remove_stopwords(\n",
    "        expnad_abb2(\n",
    "            clean_text(\n",
    "                # \"i want a lunch size pizza with no apple wood bacon but extra cheese\" #Success\n",
    "                # \"I'll order some pizza for lunch and I don't eat spaghetti I eat Pasta WIth white sauce\" # Failed\n",
    "                # \"i didn't eat from yesterday can you please order me 2 pizzas? I don't love pepperoni What about mushroom?\" #Failed\n",
    "                \"I'm not ordering pizza with extra cheese I want Soda and I don't like your organization\"\n",
    "                # \"I need pizza with extra cheese without cucumber or tomatoes add only pepperoni 'cause I love peperoni\"  # Failed\n",
    "            )\n",
    "        )\n",
    "    )\n",
    ")\n",
    "print(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmed Tokens: NOT_order  NOT_pizza  NOT_extra  NOT_chees  NOT_soda  NOT_organ  \n"
     ]
    }
   ],
   "source": [
    "stemmed_tokens = tokenize_and_lemmatize(cleaned_text)\n",
    "# print(\"Tokens:\", tokens)\n",
    "print(\"Stemmed Tokens:\", stemmed_tokens)\n",
    "# print(\"Processed String:\", processed_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_json(dataset_dir + \"PIZZA_train.json\", lines=True)\n",
    "df_dev = pd.read_json(dataset_dir + \"PIZZA_dev.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train.SRC</th>\n",
       "      <th>train.EXR</th>\n",
       "      <th>train.TOP</th>\n",
       "      <th>train.TOP-DECOUPLED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>can i have a large bbq pulled pork</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...</td>\n",
       "      <td>(ORDER can i have (PIZZAORDER (NUMBER a ) (SIZ...</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER a ) (SIZE large ) (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>large pie with green pepper and with extra pep...</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...</td>\n",
       "      <td>(ORDER (PIZZAORDER (SIZE large ) pie with (TOP...</td>\n",
       "      <td>(ORDER (PIZZAORDER (SIZE large ) (TOPPING gree...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i'd like a large vegetarian pizza</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...</td>\n",
       "      <td>(ORDER i'd like (PIZZAORDER (NUMBER a ) (SIZE ...</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER a ) (SIZE large ) (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>party size stuffed crust pie with american che...</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 1 ) (SIZE PARTY_SIZ...</td>\n",
       "      <td>(ORDER (PIZZAORDER (SIZE party size ) (STYLE s...</td>\n",
       "      <td>(ORDER (PIZZAORDER (SIZE party size ) (STYLE s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>can i have one personal sized artichoke</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 1 ) (SIZE PERSONAL_...</td>\n",
       "      <td>(ORDER can i have (PIZZAORDER (NUMBER one ) (S...</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER one ) (SIZE persona...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           train.SRC  \\\n",
       "0                 can i have a large bbq pulled pork   \n",
       "1  large pie with green pepper and with extra pep...   \n",
       "2                  i'd like a large vegetarian pizza   \n",
       "3  party size stuffed crust pie with american che...   \n",
       "4            can i have one personal sized artichoke   \n",
       "\n",
       "                                           train.EXR  \\\n",
       "0  (ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...   \n",
       "1  (ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...   \n",
       "2  (ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...   \n",
       "3  (ORDER (PIZZAORDER (NUMBER 1 ) (SIZE PARTY_SIZ...   \n",
       "4  (ORDER (PIZZAORDER (NUMBER 1 ) (SIZE PERSONAL_...   \n",
       "\n",
       "                                           train.TOP  \\\n",
       "0  (ORDER can i have (PIZZAORDER (NUMBER a ) (SIZ...   \n",
       "1  (ORDER (PIZZAORDER (SIZE large ) pie with (TOP...   \n",
       "2  (ORDER i'd like (PIZZAORDER (NUMBER a ) (SIZE ...   \n",
       "3  (ORDER (PIZZAORDER (SIZE party size ) (STYLE s...   \n",
       "4  (ORDER can i have (PIZZAORDER (NUMBER one ) (S...   \n",
       "\n",
       "                                 train.TOP-DECOUPLED  \n",
       "0  (ORDER (PIZZAORDER (NUMBER a ) (SIZE large ) (...  \n",
       "1  (ORDER (PIZZAORDER (SIZE large ) (TOPPING gree...  \n",
       "2  (ORDER (PIZZAORDER (NUMBER a ) (SIZE large ) (...  \n",
       "3  (ORDER (PIZZAORDER (SIZE party size ) (STYLE s...  \n",
       "4  (ORDER (PIZZAORDER (NUMBER one ) (SIZE persona...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dev.SRC</th>\n",
       "      <th>dev.EXR</th>\n",
       "      <th>dev.TOP</th>\n",
       "      <th>dev.PCFG_ERR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i want to order two medium pizzas with sausage...</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 2 ) (SIZE MEDIUM ) ...</td>\n",
       "      <td>(ORDER i want to order (PIZZAORDER (NUMBER two...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>five medium pizzas with tomatoes and ham</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 5 ) (SIZE MEDIUM ) ...</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER five ) (SIZE medium...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i need to order one large vegetarian pizza wit...</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...</td>\n",
       "      <td>(ORDER i need to order (PIZZAORDER (NUMBER one...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i'd like to order a large onion and pepper pizza</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...</td>\n",
       "      <td>(ORDER i'd like to order (PIZZAORDER (NUMBER a...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i'll have one pie along with pesto and ham but...</td>\n",
       "      <td>(ORDER (PIZZAORDER (NOT (TOPPING OLIVES ) ) (N...</td>\n",
       "      <td>(ORDER i'll have (PIZZAORDER (NUMBER one ) pie...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             dev.SRC  \\\n",
       "0  i want to order two medium pizzas with sausage...   \n",
       "1           five medium pizzas with tomatoes and ham   \n",
       "2  i need to order one large vegetarian pizza wit...   \n",
       "3   i'd like to order a large onion and pepper pizza   \n",
       "4  i'll have one pie along with pesto and ham but...   \n",
       "\n",
       "                                             dev.EXR  \\\n",
       "0  (ORDER (PIZZAORDER (NUMBER 2 ) (SIZE MEDIUM ) ...   \n",
       "1  (ORDER (PIZZAORDER (NUMBER 5 ) (SIZE MEDIUM ) ...   \n",
       "2  (ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...   \n",
       "3  (ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...   \n",
       "4  (ORDER (PIZZAORDER (NOT (TOPPING OLIVES ) ) (N...   \n",
       "\n",
       "                                             dev.TOP dev.PCFG_ERR  \n",
       "0  (ORDER i want to order (PIZZAORDER (NUMBER two...        False  \n",
       "1  (ORDER (PIZZAORDER (NUMBER five ) (SIZE medium...        False  \n",
       "2  (ORDER i need to order (PIZZAORDER (NUMBER one...        False  \n",
       "3  (ORDER i'd like to order (PIZZAORDER (NUMBER a...        False  \n",
       "4  (ORDER i'll have (PIZZAORDER (NUMBER one ) pie...        False  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train.SRC</th>\n",
       "      <th>train.EXR</th>\n",
       "      <th>train.TOP</th>\n",
       "      <th>train.TOP-DECOUPLED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>can i have a large bbq pulled pork</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...</td>\n",
       "      <td>(ORDER can i have (PIZZAORDER (NUMBER a ) (SIZ...</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER a ) (SIZE large ) (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>large pie with green pepper and with extra pep...</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...</td>\n",
       "      <td>(ORDER (PIZZAORDER (SIZE large ) pie with (TOP...</td>\n",
       "      <td>(ORDER (PIZZAORDER (SIZE large ) (TOPPING gree...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i'd like a large vegetarian pizza</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...</td>\n",
       "      <td>(ORDER i'd like (PIZZAORDER (NUMBER a ) (SIZE ...</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER a ) (SIZE large ) (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>party size stuffed crust pie with american che...</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 1 ) (SIZE PARTY_SIZ...</td>\n",
       "      <td>(ORDER (PIZZAORDER (SIZE party size ) (STYLE s...</td>\n",
       "      <td>(ORDER (PIZZAORDER (SIZE party size ) (STYLE s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>can i have one personal sized artichoke</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 1 ) (SIZE PERSONAL_...</td>\n",
       "      <td>(ORDER can i have (PIZZAORDER (NUMBER one ) (S...</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER one ) (SIZE persona...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           train.SRC  \\\n",
       "0                 can i have a large bbq pulled pork   \n",
       "1  large pie with green pepper and with extra pep...   \n",
       "2                  i'd like a large vegetarian pizza   \n",
       "3  party size stuffed crust pie with american che...   \n",
       "4            can i have one personal sized artichoke   \n",
       "\n",
       "                                           train.EXR  \\\n",
       "0  (ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...   \n",
       "1  (ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...   \n",
       "2  (ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...   \n",
       "3  (ORDER (PIZZAORDER (NUMBER 1 ) (SIZE PARTY_SIZ...   \n",
       "4  (ORDER (PIZZAORDER (NUMBER 1 ) (SIZE PERSONAL_...   \n",
       "\n",
       "                                           train.TOP  \\\n",
       "0  (ORDER can i have (PIZZAORDER (NUMBER a ) (SIZ...   \n",
       "1  (ORDER (PIZZAORDER (SIZE large ) pie with (TOP...   \n",
       "2  (ORDER i'd like (PIZZAORDER (NUMBER a ) (SIZE ...   \n",
       "3  (ORDER (PIZZAORDER (SIZE party size ) (STYLE s...   \n",
       "4  (ORDER can i have (PIZZAORDER (NUMBER one ) (S...   \n",
       "\n",
       "                                 train.TOP-DECOUPLED  \n",
       "0  (ORDER (PIZZAORDER (NUMBER a ) (SIZE large ) (...  \n",
       "1  (ORDER (PIZZAORDER (SIZE large ) (TOPPING gree...  \n",
       "2  (ORDER (PIZZAORDER (NUMBER a ) (SIZE large ) (...  \n",
       "3  (ORDER (PIZZAORDER (SIZE party size ) (STYLE s...  \n",
       "4  (ORDER (PIZZAORDER (NUMBER one ) (SIZE persona...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"train.SRC\"] = df_train[\"train.SRC\"].apply(clean_text)\n",
    "df_dev[\"dev.SRC\"] = df_dev[\"dev.SRC\"].apply(clean_text)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatizer = WordNetLemmatizer()\n",
    "# df_train['train.SRC'] = df_train['train.SRC'].apply(lemmatizer.lemmatize)\n",
    "# df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train.SRC</th>\n",
       "      <th>train.EXR</th>\n",
       "      <th>train.TOP</th>\n",
       "      <th>train.TOP-DECOUPLED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>can i have a large bbq pulled pork</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...</td>\n",
       "      <td>(ORDER can i have (PIZZAORDER (NUMBER a ) (SIZ...</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER a ) (SIZE large ) (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>large pie with green pepper and with extra pep...</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...</td>\n",
       "      <td>(ORDER (PIZZAORDER (SIZE large ) pie with (TOP...</td>\n",
       "      <td>(ORDER (PIZZAORDER (SIZE large ) (TOPPING gree...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i would like a large vegetarian pizza</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...</td>\n",
       "      <td>(ORDER i'd like (PIZZAORDER (NUMBER a ) (SIZE ...</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER a ) (SIZE large ) (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>party size stuffed crust pie with american che...</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 1 ) (SIZE PARTY_SIZ...</td>\n",
       "      <td>(ORDER (PIZZAORDER (SIZE party size ) (STYLE s...</td>\n",
       "      <td>(ORDER (PIZZAORDER (SIZE party size ) (STYLE s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>can i have one personal sized artichoke</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 1 ) (SIZE PERSONAL_...</td>\n",
       "      <td>(ORDER can i have (PIZZAORDER (NUMBER one ) (S...</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER one ) (SIZE persona...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           train.SRC  \\\n",
       "0                 can i have a large bbq pulled pork   \n",
       "1  large pie with green pepper and with extra pep...   \n",
       "2              i would like a large vegetarian pizza   \n",
       "3  party size stuffed crust pie with american che...   \n",
       "4            can i have one personal sized artichoke   \n",
       "\n",
       "                                           train.EXR  \\\n",
       "0  (ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...   \n",
       "1  (ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...   \n",
       "2  (ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...   \n",
       "3  (ORDER (PIZZAORDER (NUMBER 1 ) (SIZE PARTY_SIZ...   \n",
       "4  (ORDER (PIZZAORDER (NUMBER 1 ) (SIZE PERSONAL_...   \n",
       "\n",
       "                                           train.TOP  \\\n",
       "0  (ORDER can i have (PIZZAORDER (NUMBER a ) (SIZ...   \n",
       "1  (ORDER (PIZZAORDER (SIZE large ) pie with (TOP...   \n",
       "2  (ORDER i'd like (PIZZAORDER (NUMBER a ) (SIZE ...   \n",
       "3  (ORDER (PIZZAORDER (SIZE party size ) (STYLE s...   \n",
       "4  (ORDER can i have (PIZZAORDER (NUMBER one ) (S...   \n",
       "\n",
       "                                 train.TOP-DECOUPLED  \n",
       "0  (ORDER (PIZZAORDER (NUMBER a ) (SIZE large ) (...  \n",
       "1  (ORDER (PIZZAORDER (SIZE large ) (TOPPING gree...  \n",
       "2  (ORDER (PIZZAORDER (NUMBER a ) (SIZE large ) (...  \n",
       "3  (ORDER (PIZZAORDER (SIZE party size ) (STYLE s...  \n",
       "4  (ORDER (PIZZAORDER (NUMBER one ) (SIZE persona...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"train.SRC\"] = df_train[\"train.SRC\"].apply(expnad_abb2)\n",
    "df_dev[\"dev.SRC\"] = df_dev[\"dev.SRC\"].apply(expnad_abb2)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train.SRC</th>\n",
       "      <th>train.EXR</th>\n",
       "      <th>train.TOP</th>\n",
       "      <th>train.TOP-DECOUPLED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>large bbq pulled pork</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...</td>\n",
       "      <td>(ORDER can i have (PIZZAORDER (NUMBER a ) (SIZ...</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER a ) (SIZE large ) (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>large pie green pepper and extra peperonni</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...</td>\n",
       "      <td>(ORDER (PIZZAORDER (SIZE large ) pie with (TOP...</td>\n",
       "      <td>(ORDER (PIZZAORDER (SIZE large ) (TOPPING gree...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>large vegetarian pizza</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...</td>\n",
       "      <td>(ORDER i'd like (PIZZAORDER (NUMBER a ) (SIZE ...</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER a ) (SIZE large ) (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>party size stuffed crust pie american cheese a...</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 1 ) (SIZE PARTY_SIZ...</td>\n",
       "      <td>(ORDER (PIZZAORDER (SIZE party size ) (STYLE s...</td>\n",
       "      <td>(ORDER (PIZZAORDER (SIZE party size ) (STYLE s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>one personal sized artichoke</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 1 ) (SIZE PERSONAL_...</td>\n",
       "      <td>(ORDER can i have (PIZZAORDER (NUMBER one ) (S...</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER one ) (SIZE persona...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           train.SRC  \\\n",
       "0                              large bbq pulled pork   \n",
       "1         large pie green pepper and extra peperonni   \n",
       "2                             large vegetarian pizza   \n",
       "3  party size stuffed crust pie american cheese a...   \n",
       "4                       one personal sized artichoke   \n",
       "\n",
       "                                           train.EXR  \\\n",
       "0  (ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...   \n",
       "1  (ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...   \n",
       "2  (ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...   \n",
       "3  (ORDER (PIZZAORDER (NUMBER 1 ) (SIZE PARTY_SIZ...   \n",
       "4  (ORDER (PIZZAORDER (NUMBER 1 ) (SIZE PERSONAL_...   \n",
       "\n",
       "                                           train.TOP  \\\n",
       "0  (ORDER can i have (PIZZAORDER (NUMBER a ) (SIZ...   \n",
       "1  (ORDER (PIZZAORDER (SIZE large ) pie with (TOP...   \n",
       "2  (ORDER i'd like (PIZZAORDER (NUMBER a ) (SIZE ...   \n",
       "3  (ORDER (PIZZAORDER (SIZE party size ) (STYLE s...   \n",
       "4  (ORDER can i have (PIZZAORDER (NUMBER one ) (S...   \n",
       "\n",
       "                                 train.TOP-DECOUPLED  \n",
       "0  (ORDER (PIZZAORDER (NUMBER a ) (SIZE large ) (...  \n",
       "1  (ORDER (PIZZAORDER (SIZE large ) (TOPPING gree...  \n",
       "2  (ORDER (PIZZAORDER (NUMBER a ) (SIZE large ) (...  \n",
       "3  (ORDER (PIZZAORDER (SIZE party size ) (STYLE s...  \n",
       "4  (ORDER (PIZZAORDER (NUMBER one ) (SIZE persona...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"train.SRC\"] = df_train[\"train.SRC\"].apply(remove_stopwords)\n",
    "df_dev[\"dev.SRC\"] = df_dev[\"dev.SRC\"].apply(remove_stopwords)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train.SRC</th>\n",
       "      <th>train.EXR</th>\n",
       "      <th>train.TOP</th>\n",
       "      <th>train.TOP-DECOUPLED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>can i have a large bbq pulled pork</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...</td>\n",
       "      <td>(ORDER can i have (PIZZAORDER (NUMBER a ) (SIZ...</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER a ) (SIZE large ) (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>large pie with green pepper with extra peperonni</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...</td>\n",
       "      <td>(ORDER (PIZZAORDER (SIZE large ) pie with (TOP...</td>\n",
       "      <td>(ORDER (PIZZAORDER (SIZE large ) (TOPPING gree...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i would like a large vegetarian pizza</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...</td>\n",
       "      <td>(ORDER i'd like (PIZZAORDER (NUMBER a ) (SIZE ...</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER a ) (SIZE large ) (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>party size stuffed crust pie with american che...</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 1 ) (SIZE PARTY_SIZ...</td>\n",
       "      <td>(ORDER (PIZZAORDER (SIZE party size ) (STYLE s...</td>\n",
       "      <td>(ORDER (PIZZAORDER (SIZE party size ) (STYLE s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>can i have one personal sized artichoke</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 1 ) (SIZE PERSONAL_...</td>\n",
       "      <td>(ORDER can i have (PIZZAORDER (NUMBER one ) (S...</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER one ) (SIZE persona...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           train.SRC  \\\n",
       "0                 can i have a large bbq pulled pork   \n",
       "1   large pie with green pepper with extra peperonni   \n",
       "2              i would like a large vegetarian pizza   \n",
       "3  party size stuffed crust pie with american che...   \n",
       "4            can i have one personal sized artichoke   \n",
       "\n",
       "                                           train.EXR  \\\n",
       "0  (ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...   \n",
       "1  (ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...   \n",
       "2  (ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...   \n",
       "3  (ORDER (PIZZAORDER (NUMBER 1 ) (SIZE PARTY_SIZ...   \n",
       "4  (ORDER (PIZZAORDER (NUMBER 1 ) (SIZE PERSONAL_...   \n",
       "\n",
       "                                           train.TOP  \\\n",
       "0  (ORDER can i have (PIZZAORDER (NUMBER a ) (SIZ...   \n",
       "1  (ORDER (PIZZAORDER (SIZE large ) pie with (TOP...   \n",
       "2  (ORDER i'd like (PIZZAORDER (NUMBER a ) (SIZE ...   \n",
       "3  (ORDER (PIZZAORDER (SIZE party size ) (STYLE s...   \n",
       "4  (ORDER can i have (PIZZAORDER (NUMBER one ) (S...   \n",
       "\n",
       "                                 train.TOP-DECOUPLED  \n",
       "0  (ORDER (PIZZAORDER (NUMBER a ) (SIZE large ) (...  \n",
       "1  (ORDER (PIZZAORDER (SIZE large ) (TOPPING gree...  \n",
       "2  (ORDER (PIZZAORDER (NUMBER a ) (SIZE large ) (...  \n",
       "3  (ORDER (PIZZAORDER (SIZE party size ) (STYLE s...  \n",
       "4  (ORDER (PIZZAORDER (NUMBER one ) (SIZE persona...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"train.SRC\"] = df_train[\"train.SRC\"].apply(handle_negation)\n",
    "df_dev[\"dev.SRC\"] = df_dev[\"dev.SRC\"].apply(handle_negation)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train.SRC</th>\n",
       "      <th>train.EXR</th>\n",
       "      <th>train.TOP</th>\n",
       "      <th>train.TOP-DECOUPLED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>can  i  have  a  larg  bbq  pull  pork</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...</td>\n",
       "      <td>(ORDER can i have (PIZZAORDER (NUMBER a ) (SIZ...</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER a ) (SIZE large ) (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>larg  pie  with  green  pepper  with  extra  p...</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...</td>\n",
       "      <td>(ORDER (PIZZAORDER (SIZE large ) pie with (TOP...</td>\n",
       "      <td>(ORDER (PIZZAORDER (SIZE large ) (TOPPING gree...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i  would  like  a  larg  vegetarian  pizza</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...</td>\n",
       "      <td>(ORDER i'd like (PIZZAORDER (NUMBER a ) (SIZE ...</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER a ) (SIZE large ) (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>parti  size  stuf  crust  pie  with  american ...</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 1 ) (SIZE PARTY_SIZ...</td>\n",
       "      <td>(ORDER (PIZZAORDER (SIZE party size ) (STYLE s...</td>\n",
       "      <td>(ORDER (PIZZAORDER (SIZE party size ) (STYLE s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>can  i  have  one  person  size  artichok</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 1 ) (SIZE PERSONAL_...</td>\n",
       "      <td>(ORDER can i have (PIZZAORDER (NUMBER one ) (S...</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER one ) (SIZE persona...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           train.SRC  \\\n",
       "0           can  i  have  a  larg  bbq  pull  pork     \n",
       "1  larg  pie  with  green  pepper  with  extra  p...   \n",
       "2       i  would  like  a  larg  vegetarian  pizza     \n",
       "3  parti  size  stuf  crust  pie  with  american ...   \n",
       "4        can  i  have  one  person  size  artichok     \n",
       "\n",
       "                                           train.EXR  \\\n",
       "0  (ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...   \n",
       "1  (ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...   \n",
       "2  (ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (...   \n",
       "3  (ORDER (PIZZAORDER (NUMBER 1 ) (SIZE PARTY_SIZ...   \n",
       "4  (ORDER (PIZZAORDER (NUMBER 1 ) (SIZE PERSONAL_...   \n",
       "\n",
       "                                           train.TOP  \\\n",
       "0  (ORDER can i have (PIZZAORDER (NUMBER a ) (SIZ...   \n",
       "1  (ORDER (PIZZAORDER (SIZE large ) pie with (TOP...   \n",
       "2  (ORDER i'd like (PIZZAORDER (NUMBER a ) (SIZE ...   \n",
       "3  (ORDER (PIZZAORDER (SIZE party size ) (STYLE s...   \n",
       "4  (ORDER can i have (PIZZAORDER (NUMBER one ) (S...   \n",
       "\n",
       "                                 train.TOP-DECOUPLED  \n",
       "0  (ORDER (PIZZAORDER (NUMBER a ) (SIZE large ) (...  \n",
       "1  (ORDER (PIZZAORDER (SIZE large ) (TOPPING gree...  \n",
       "2  (ORDER (PIZZAORDER (NUMBER a ) (SIZE large ) (...  \n",
       "3  (ORDER (PIZZAORDER (SIZE party size ) (STYLE s...  \n",
       "4  (ORDER (PIZZAORDER (NUMBER one ) (SIZE persona...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"train.SRC\"] = df_train[\"train.SRC\"].apply(tokenize_and_lemmatize)\n",
    "df_dev[\"dev.SRC\"] = df_dev[\"dev.SRC\"].apply(tokenize_and_lemmatize)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_data = df_train[\"train.SRC\"]\n",
    "\n",
    "tf_idf_data = vectorizer.fit_transform(tf_idf_data)\n",
    "tf_idf_data = tf_idf_data.toarray()\n",
    "# tf_idf_data = tf_idf_data.apply(vectorizer.fit_transform)\n",
    "# X_train_tfidf = vectorizer.fit_transform(temp_data)\n",
    "# X_test_tfidf = vectorizer.transform(temp_data)\n",
    "# print(X_train_tfidf)\n",
    "# print(tf_idf_data)\n",
    "# df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['10' '11' '12' '13' '14' '15' '16' '20' '200' '500' 'ale' 'alfredo' 'all'\n",
      " 'also' 'american' 'an' 'anchovi' 'appl' 'applewood' 'artichok' 'arugula'\n",
      " 'bacon' 'balsam' 'balzam' 'banana' 'barbecu' 'basil' 'bay' 'bbq' 'bean'\n",
      " 'beef' 'big' 'bit' 'black' 'bottl' 'broccoli' 'brocoli' 'buffalo' 'can'\n",
      " 'caramel' 'carrot' 'cauliflow' 'cheddar' 'chees' 'cheeseburg' 'cherri'\n",
      " 'chicago' 'chicken' 'chorizo' 'chorrizo' 'coffe' 'coke' 'combin' 'crust'\n",
      " 'cumin' 'deep' 'deepdish' 'dew' 'diet' 'dish' 'doctor' 'dough' 'dr' 'dri'\n",
      " 'eight' 'eleven' 'everi' 'everyth' 'extra' 'fanta' 'fat' 'feta' 'fifteen'\n",
      " 'five' 'fl' 'flake' 'fluid' 'four' 'fourteen' 'free' 'fri' 'garlic'\n",
      " 'ginger' 'glaze' 'gluten' 'green' 'grill' 'ground' 'ham' 'have'\n",
      " 'hawaiian' 'high' 'hot' 'ice' 'in' 'italian' 'jalapeno' 'just' 'kalamata'\n",
      " 'keto' 'larg' 'leav' 'lemon' 'lettuc' 'like' 'liter' 'littl' 'lot'\n",
      " 'lover' 'low' 'lunch' 'margarita' 'margherita' 'meat' 'meatbal' 'meatlov'\n",
      " 'med' 'mediterranean' 'medium' 'mexican' 'millilit' 'ml' 'mountain'\n",
      " 'mozarella' 'mozzarella' 'mushroom' 'napolitan' 'napolitana' 'neapolitan'\n",
      " 'need' 'new' 'nine' 'not_alfredo' 'not_american' 'not_anchovi' 'not_ani'\n",
      " 'not_appl' 'not_applewood' 'not_artichok' 'not_arugula' 'not_bacon'\n",
      " 'not_balsam' 'not_balzam' 'not_banana' 'not_barbecu' 'not_basil'\n",
      " 'not_bay' 'not_bbq' 'not_bean' 'not_beef' 'not_black' 'not_broccoli'\n",
      " 'not_brocoli' 'not_buffalo' 'not_caramel' 'not_carrot' 'not_cheddar'\n",
      " 'not_chees' 'not_cheeseburg' 'not_cherri' 'not_chicken' 'not_chorizo'\n",
      " 'not_chorrizo' 'not_crust' 'not_cumin' 'not_dri' 'not_fat' 'not_feta'\n",
      " 'not_flake' 'not_fri' 'not_garlic' 'not_glaze' 'not_green' 'not_grill'\n",
      " 'not_ground' 'not_ham' 'not_hot' 'not_italian' 'not_jalapeno'\n",
      " 'not_kalamata' 'not_leav' 'not_lettuc' 'not_low' 'not_mani' 'not_meatbal'\n",
      " 'not_mozarella' 'not_mozzarella' 'not_much' 'not_mushroom' 'not_oil'\n",
      " 'not_oliv' 'not_onion' 'not_oregano' 'not_parmesan' 'not_parsley'\n",
      " 'not_pea' 'not_pecorino' 'not_peperoni' 'not_peperonni' 'not_peperroni'\n",
      " 'not_peperronni' 'not_pepper' 'not_pepperoni' 'not_peppperoni'\n",
      " 'not_pesto' 'not_pickl' 'not_pineapl' 'not_pineappl' 'not_pork'\n",
      " 'not_powder' 'not_pull' 'not_ranch' 'not_red' 'not_ricotta' 'not_roast'\n",
      " 'not_rosemari' 'not_salami' 'not_sauc' 'not_sausag' 'not_shrimp'\n",
      " 'not_spice' 'not_spici' 'not_spinach' 'not_the' 'not_thin' 'not_tomato'\n",
      " 'not_tuna' 'not_vegan' 'not_white' 'not_wood' 'not_yellow' 'of' 'oil'\n",
      " 'oliv' 'one' 'onion' 'onli' 'oregano' 'ounc' 'oz' 'pan' 'parmesan'\n",
      " 'parsley' 'parti' 'pea' 'pecorino' 'pellegrino' 'peper' 'peperoni'\n",
      " 'peperonni' 'peperroni' 'peperronni' 'pepper' 'pepperoni' 'peppperoni'\n",
      " 'pepsi' 'perrier' 'person' 'pesto' 'pickl' 'pie' 'pineapl' 'pineappl'\n",
      " 'pizza' 'pork' 'powder' 'pull' 'ranch' 'red' 'regular' 'ricotta' 'rise'\n",
      " 'roast' 'rosemari' 'salami' 'san' 'sauc' 'sausag' 'seven' 'shrimp' 'six'\n",
      " 'sixteen' 'size' 'small' 'soda' 'sourdough' 'spice' 'spici' 'spinach'\n",
      " 'sprite' 'stuf' 'style' 'suprem' 'tea' 'ten' 'the' 'thick' 'thin'\n",
      " 'thirteen' 'three' 'tini' 'tomato' 'top' 'tuna' 'twelv' 'two' 'up'\n",
      " 'vegan' 'veget' 'vegetarian' 'veggi' 'want' 'water' 'white' 'with' 'wood'\n",
      " 'work' 'would' 'yellow' 'york' 'yorker' 'zero']\n",
      "Document-Term Matrix:\n",
      " [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initialize the CountVectorizer\n",
    "count_vectroizer = CountVectorizer()\n",
    "\n",
    "bow = df_train[\"train.SRC\"]\n",
    "\n",
    "# Fit and transform the corpus to a document-term matrix\n",
    "X = count_vectroizer.fit_transform(bow)\n",
    "\n",
    "vocab = count_vectroizer.get_feature_names_out()\n",
    "\n",
    "X_dense = X.toarray()\n",
    "# Print the vocabulary and document-term matrix\n",
    "print(\"Vocabulary:\", vocab)\n",
    "print(\"Document-Term Matrix:\\n\", X_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneHotEncoder(sparse_output=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Initialize OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "temp_data = df_train[\"train.SRC\"].head(20)\n",
    "# Fit and transform the categorical columns\n",
    "one_hot_encoded = encoder.fit([temp_data])\n",
    "print(one_hot_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_features = np.concatenate([tf_idf_data, X_dense], axis=1)  # Shape: (num_samples, 2000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tokenizer = Tokenizer()\n",
    "input_tokenizer.fit_on_texts(df_train[\"train.SRC\"].head(1000))\n",
    "word_sequences = input_tokenizer.texts_to_sequences(df_train[\"train.SRC\"].head(1000))\n",
    "max_input_length = max(len(seq) for seq in word_sequences)\n",
    "word_sequences_padded = pad_sequences(word_sequences, maxlen=max_input_length, padding='post')  # Shape: (num_samples, max_length)\n",
    "\n",
    "output_tokenizer = Tokenizer(filters=\"\")\n",
    "output_tokenizer.fit_on_texts(df_train['train.EXR'])\n",
    "output_sequences = output_tokenizer.texts_to_sequences(df_train['train.EXR'].head(1000))\n",
    "max_output_length = max(len(seq) for seq in output_sequences)\n",
    "output_sequences_padded = pad_sequences(output_sequences, maxlen=max_output_length, padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yara\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = Embedding(input_dim= len(input_tokenizer.word_index) + 1 , output_dim=100, input_length=max_input_length)\n",
    "embedded_sequences = embedding_layer(word_sequences_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Only input tensors may be passed as positional arguments. The following argument value should be passed as a keyword argument: <Bidirectional name=bidirectional_2, built=False> (of type <class 'keras.src.layers.rnn.bidirectional.Bidirectional'>)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m lstm_output \u001b[38;5;241m=\u001b[39m Bidirectional(LSTM(units\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Output Layer\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mTimeDistributed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_output_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msoftmax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlstm_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Compile the Model\u001b[39;00m\n\u001b[0;32m     11\u001b[0m model \u001b[38;5;241m=\u001b[39m Model(inputs\u001b[38;5;241m=\u001b[39m[word_sequences_padded, combined_features], outputs\u001b[38;5;241m=\u001b[39moutput)\n",
      "File \u001b[1;32mc:\\Users\\Yara\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Yara\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\layer.py:808\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    802\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m tree\u001b[38;5;241m.\u001b[39mflatten(args):\n\u001b[0;32m    803\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    804\u001b[0m             \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, KerasTensor)\n\u001b[0;32m    805\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mis_tensor(arg)\n\u001b[0;32m    806\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m arg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    807\u001b[0m         ):\n\u001b[1;32m--> 808\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    809\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly input tensors may be passed as \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    810\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositional arguments. The following argument value \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    811\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshould be passed as a keyword argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    812\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(arg)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    813\u001b[0m             )\n\u001b[0;32m    815\u001b[0m \u001b[38;5;66;03m# Caches info about `call()` signature, args, kwargs.\u001b[39;00m\n\u001b[0;32m    816\u001b[0m call_spec \u001b[38;5;241m=\u001b[39m CallSpec(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_signature, args, kwargs)\n",
      "\u001b[1;31mValueError\u001b[0m: Only input tensors may be passed as positional arguments. The following argument value should be passed as a keyword argument: <Bidirectional name=bidirectional_2, built=False> (of type <class 'keras.src.layers.rnn.bidirectional.Bidirectional'>)"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import LSTM, TimeDistributed, Dense, Bidirectional\n",
    "\n",
    "# RNN Layer\n",
    "lstm_output = Bidirectional(LSTM(units=64, return_sequences=True))\n",
    "\n",
    "# Output Layer\n",
    "output = TimeDistributed(Dense(max_output_length, activation='softmax'))(lstm_output)\n",
    "\n",
    "# Compile the Model\n",
    "model = Model(inputs=[word_sequences_padded, combined_features], outputs=output)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(\n",
    "    word_sequences_padded,  # Inputs\n",
    "    output_sequences_padded,                                     # Labels\n",
    "    epochs=10,\n",
    "    batch_size=32\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gensim.models import Word2Vec, KeyedVectors\n",
    "\n",
    "# pre_trained = KeyedVectors.load_word2vec_format(\n",
    "#     \"GoogleNews-vectors-negative300.bin\", binary=True\n",
    "# )\n",
    "# # Load pre-trained Word2Vec\n",
    "# test_sentences = df_train[\"train.SRC\"].head(10000)\n",
    "\n",
    "# # Convert to Word2Vec model for fine-tuning\n",
    "# pre_trained_model = Word2Vec(min_count=1,workers=14,vector_size=300)\n",
    "\n",
    "# pre_trained_model.build_vocab(test_sentences)\n",
    "\n",
    "# # Build vocabulary from the pre-trained model's keys\n",
    "# pre_trained_model.build_vocab([list(pre_trained.key_to_index.keys())], update=True)\n",
    "\n",
    "# Initialize weights with the pre-trained vectors\n",
    "# pre_trained_model.wv.vectors = pre_trained_model.wv.vectors[\n",
    "#     : len(pre_trained_model.wv.index_to_key)\n",
    "# ]\n",
    "\n",
    "# # Step 4: Intersect with pre-trained embeddings\n",
    "# pre_trained_model.wv.intersect_word2vec_format(\n",
    "#     \"GoogleNews-vectors-negative300.bin\", binary=True, lockf=1.0\n",
    "# )\n",
    "\n",
    "\n",
    "# # Train further on your dataset\n",
    "# pre_trained_model.train(test_sentences, total_examples=len(custom_sentences), epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Index: {'<OOV>': 1, 'e': 2, 'p': 3, 'a': 4, 'i': 5, 'r': 6, 'n': 7, 'o': 8, 't': 9, 's': 10, 'z': 11, 'c': 12, 'l': 13, 'h': 14, 'm': 15, 'u': 16, 'g': 17, 'b': 18, 'd': 19, 'x': 20, 'v': 21, 'f': 22, 'k': 23, 'w': 24, 'y': 25, 'q': 26, 'j': 27}\n",
      "Padded Sequences: [[18 26  3 ...  8  6 23]\n",
      " [ 4  3  2 ...  7  7  5]\n",
      " [ 4  6  5 ... 11 11  4]\n",
      " ...\n",
      " [ 9  3  2 ...  7  7  5]\n",
      " [ 2 13  6 ...  5  8  7]\n",
      " [15  8 11 ... 13 13  4]]\n"
     ]
    }
   ],
   "source": [
    "custom_sentences = df_train[\"train.SRC\"].head(10000)\n",
    "\n",
    "tokenizer = Tokenizer(num_words=500, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(\n",
    "    [\" \".join(tokens) for tokens in custom_sentences]\n",
    ")  # Flatten sentences for Keras\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "sequences_train = tokenizer.texts_to_sequences(\n",
    "    [\" \".join(tokens) for tokens in custom_sentences]\n",
    ")  # transforms each text in texts to a sequence of integers\n",
    "padded_sequences_train = pad_sequences(sequences_train, maxlen=10, padding=\"post\")\n",
    "\n",
    "print(\"Word Index:\", word_index)\n",
    "print(\"Padded Sequences:\", padded_sequences_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(\n",
    "    sentences=custom_sentences, min_count=1, workers=14, vector_size=300\n",
    ")\n",
    "\n",
    "embedding_dim = w2v_model.vector_size  # Size of Word2Vec embeddings\n",
    "vocab_size = len(word_index) + 1  # Add 1 for padding token\n",
    "\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    if word in w2v_model.wv:\n",
    "        embedding_matrix[i] = w2v_model.wv[word]  # Assign pre-trained vector\n",
    "    else:\n",
    "        embedding_matrix[i] = np.random.normal(\n",
    "            size=(embedding_dim,)\n",
    "        )  # Random vector for unknown words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Index: {'<OOV>': 1, 'e': 2, 'p': 3, 'r': 4, 'i': 5, 'o': 6, 'n': 7, 't': 8, 'a': 9, 'z': 10, 's': 11, 'g': 12, 'd': 13, 'm': 14, 'c': 15, 'l': 16, 'u': 17, 'b': 18, 'y': 19, '1': 20, 'h': 21, 'x': 22, 'q': 23, 'f': 24, 'k': 25, 'v': 26, 'w': 27, 'j': 28}\n",
      "Padded Sequences: [[ 3 17 16 ...  6  4 25]\n",
      " [12  3  2 ...  6  7  5]\n",
      " [26  2 12 ...  5  9  7]\n",
      " ...\n",
      " [12  3  2 ...  6  7  5]\n",
      " [ 5 10  2 ...  6  7 11]\n",
      " [ 2 16 16 ...  2 11  2]]\n"
     ]
    }
   ],
   "source": [
    "test_sentences = df_train[\"train.EXR\"].head(10000)\n",
    "\n",
    "tokenizer = Tokenizer(num_words=500, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(\n",
    "    [\" \".join(tokens) for tokens in test_sentences]\n",
    ")  # Flatten sentences for Keras\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(\n",
    "    [\" \".join(tokens) for tokens in test_sentences]\n",
    ")  # transforms each text in texts to a sequence of integers\n",
    "padded_sequences = pad_sequences(sequences, maxlen=10, padding=\"post\")\n",
    "\n",
    "print(\"Word Index:\", word_index)\n",
    "print(\"Padded Sequences:\", padded_sequences)\n",
    "embedding_dim = w2v_model.vector_size  # Size of Word2Vec embeddings\n",
    "vocab_size = len(word_index) + 1  # Add 1 for padding token\n",
    "\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    if word in w2v_model.wv:\n",
    "        embedding_matrix[i] = w2v_model.wv[word]  # Assign pre-trained vector\n",
    "    else:\n",
    "        embedding_matrix[i] = np.random.normal(\n",
    "            size=(embedding_dim,)\n",
    "        )  # Random vector for unknown words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = Sequential(\n",
    "    [\n",
    "        Embedding(\n",
    "            input_dim=vocab_size,\n",
    "            output_dim=embedding_dim,\n",
    "            weights=[embedding_matrix],\n",
    "            input_length=padded_sequences_train.shape[1],\n",
    "            trainable=False,\n",
    "        ),\n",
    "        LSTM(128, return_sequences=False),\n",
    "        Dense(padded_sequences_train.shape[1], activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 3s - 10ms/step - accuracy: 0.2338 - loss: 236.8394\n",
      "Epoch 2/10\n",
      "313/313 - 2s - 5ms/step - accuracy: 0.2360 - loss: 244.8951\n",
      "Epoch 3/10\n",
      "313/313 - 2s - 5ms/step - accuracy: 0.2360 - loss: 247.0565\n",
      "Epoch 4/10\n",
      "313/313 - 2s - 5ms/step - accuracy: 0.2360 - loss: 248.9971\n",
      "Epoch 5/10\n",
      "313/313 - 2s - 5ms/step - accuracy: 0.2360 - loss: 250.9110\n",
      "Epoch 6/10\n",
      "313/313 - 2s - 5ms/step - accuracy: 0.2360 - loss: 252.8540\n",
      "Epoch 7/10\n",
      "313/313 - 2s - 5ms/step - accuracy: 0.2360 - loss: 254.8490\n",
      "Epoch 8/10\n",
      "313/313 - 2s - 5ms/step - accuracy: 0.2360 - loss: 256.9070\n",
      "Epoch 9/10\n",
      "313/313 - 2s - 5ms/step - accuracy: 0.2360 - loss: 259.0325\n",
      "Epoch 10/10\n",
      "313/313 - 2s - 6ms/step - accuracy: 0.2360 - loss: 261.2292\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    padded_sequences_train,  # Input sequences (numerical)\n",
    "    padded_sequences,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    # validation_data=(test_padded, test_labels),  # Validation data\n",
    "    verbose=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model architecture\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(units=32, input_shape=(None, 1)))\n",
    "model.add(Dense(units=1, activation=\"sigmoid\"))\n",
    "# Compile the model\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=32)\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "# Make predictions using the model\n",
    "predictions = model.predict(x_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, activation=\"relu\", input_shape=(n_input, n_features)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "model.summary()\n",
    "model.fit(generator, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=500, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(\n",
    "    # df_train[\"train.SRC\"]\n",
    "    df_train[\"train.SRC\"].head(10)\n",
    ")  # updates internal vocabulary based on a list of texts\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(\n",
    "    df_train[\"train.SRC\"]\n",
    ")  # transforms each text in texts to a sequence of integers\n",
    "padded_sequences = pad_sequences(sequences, maxlen=100, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"padded_seq\"] = list(padded_sequences)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
